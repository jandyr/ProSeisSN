{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeMSvOAPfX5S"
   },
   "source": [
    "# ---\n",
    "# Unit11: Ambient Noise Tomography\n",
    "\n",
    "This notebook has the activities of the Course **ProSeisSN**. It deals with time series processing using a passive seismic dataset using [ObsPy](https://docs.obspy.org/).\n",
    "\n",
    "#### Dependencies: Obspy, Numpy, Matplotlib\n",
    "#### Reset the Jupyter notebook in order to run it again, press:\n",
    "***Kernel*** -> ***Restart & Clear Output***\n",
    "#### The code $\\Downarrow$ BELOW $\\Downarrow$ runs a notebook with other dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "uzMJ-lGlkGuK",
    "outputId": "66c27f9e-fd21-4a54-ed6d-6a23b77ec540",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#------ Import Libraries\n",
    "import sys\n",
    "import os\n",
    "    \n",
    "#------ Work with the directory structure to include auxiliary codes\n",
    "print('\\n Local directory ==> ', os.getcwd())\n",
    "print('  - Contents: ', os.listdir(), '\\n')\n",
    "\n",
    "path = os.path.abspath(os.path.join('..'))\n",
    "if path not in sys.path:\n",
    "    sys.path.append(path+\"/CodePy\")\n",
    "\n",
    "%run ../CodePy/ImpMod.ipynb\n",
    "\n",
    "#------ Alter default matplotlib rcParams\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.dates as dates\n",
    "# Change the defaults of the runtime configuration settings in the global variable matplotlib.rcParams\n",
    "plt.rcParams['figure.figsize'] = 9, 5\n",
    "#plt.rcParams['lines.linewidth'] = 0.5\n",
    "plt.rcParams[\"figure.subplot.hspace\"] = (.9)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "#------ Magic commands\n",
    "%matplotlib inline\n",
    "%matplotlib widget\n",
    "#%pylab notebook\n",
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Read data files from TTB22 as SEG2. Create a new stream from the SEG2 stream\n",
    "- Read phone positions\n",
    "- Select and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================== READ PHONES LOCATIONS ======================\n",
    "\"\"\"\n",
    "#------ Read the phones cartesian locations\n",
    "#--- Reads the CSV file with (x, y)m locations\n",
    "ttb_loc = u.RGloc('../Data/'+'ttb_loc.dat')\n",
    "#------ Read the phones geographic locations\n",
    "#--- Reads the CSV file with (lat,lon) in degress locations\n",
    "ttb_gloc = u.RGloc('../Data/'+'ttb_gloc.dat')\n",
    "#\n",
    "#------ Plot gather in cartesian\n",
    "p.pgather(ttb_loc[:,1], ttb_loc[:,2], ttb_loc[:,0], coord='cartesian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================== READ THE SEISMIC DATA LOCALLY ======================\n",
    "File hints:\n",
    "3710 and 3720 -> several events\n",
    "3740 -> 2 events\n",
    "3790 -> 1 event (6-9)s\n",
    "\"\"\"\n",
    "#------ Read the seismic data\n",
    "ent = str(np.random.choice(np.arange(3700, 3811, 10)))\n",
    "ent = input(f'   Enter a file number in [3695, 3810], rtn=random:\\n') or ent\n",
    "ent = ent.rstrip().split(' ')\n",
    "print(f\">> Read with data file {ent}\")\n",
    "ent = '../Data/ttb/'+ent[0]+'.dat'\n",
    "#\n",
    "#------- Read the data file as a SEG2 object.\n",
    "st     = read(ent)\n",
    "#\n",
    "#------- Print stream information\n",
    "dummy = float(st[-1].stats.seg2.RECEIVER_LOCATION)\n",
    "print(f\">> Gather acquired on {st[0].stats.starttime}, has {int(st[0].stats.npts)} data points.\")\n",
    "\"\"\"\n",
    "================= Create a new stream from the SEG2 stream ======================\n",
    "                         Retain a gather copy\n",
    "\"\"\"\n",
    "#------ Create a new stream from the SEG2 stream.\n",
    "#       1) Adds coordinates to gather. Stores a copy in gather0\n",
    "#       2) Gather baricenter = bcenter.\n",
    "gather, bcenter = u.creastrm(st, ttb_gloc)\n",
    "gather0 = gather.copy()\n",
    "#\n",
    "#--- Phone choice\n",
    "phone = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data processing\n",
    "- Filter data\n",
    "- Display the seismogram\n",
    "### Filter and look at seismogram and to the frequency content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\"\"\"\n",
    "================= Filter data and look at the frequency contents ======================\n",
    "                    Create a new stream from the SEG2 stream\n",
    "\"\"\"\n",
    "#\n",
    "#------- Remove mean and trend + filter the stream\n",
    "#--- Filter parameters: change them as you wish.\n",
    "MTparam = [ 1,   1,    'bp',  10.,   40.,   0,    0]\n",
    "# └─────> [dtr, line, ftype, Fmin, Fmax, taper, gain]\n",
    "#                                          └─> data will be windowed at trace normalization and spectral whitening\n",
    "ent = str(MTparam[3]) + ' ' + str(MTparam[4])\n",
    "ent = input(f'\\n Enter filter min and max frequencies (dflt = {MTparam[3]}, {MTparam[4]})') or ent\n",
    "ent = ent.rstrip().split(' ')\n",
    "MTparam[3], MTparam[4] = [float(dummy) for dummy in ent]\n",
    "#\n",
    "gather = u.otrstr(gather, MTparam)\n",
    "#\n",
    "#------- Check frequency contents to accept preprocessing\n",
    "#--- Pick up a random phone/trace\n",
    "phone = phone if phone is not None else np.random.randint(1, len(gather)+1)\n",
    "print(f' Random phone {phone} ')\n",
    "#--- Go to trace instead of phone: trace = phone -1\n",
    "phone = phone - 1\n",
    "#--- Relative time: nummpy array\n",
    "time = gather[phone].times(type=\"relative\")\n",
    "#--- Plot Trace+Spectrogram\n",
    "p.Pspect(time, gather[phone])\n",
    "#\n",
    "#------- Once filtering is accepted create a new backup for gather\n",
    "ent = input(f' Run this cell again (rtn= No, else plot Spectrogram)?: ') or False\n",
    "if not ent:\n",
    "    gather0 = gather.copy()\n",
    "    print(f' A new stream backup was created.')\n",
    "else:\n",
    "    gather = gather0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================== Plot Seismogram ======================\n",
    "\"\"\"\n",
    "gather.plot(type='section',\n",
    "            scale=1.3, alpha=.7,\n",
    "            orientation='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================== Zoom in to select [t0, t1]======================\n",
    "\"\"\"\n",
    "#------ Zoom in the seismogram\n",
    "\n",
    "ent = input(f' Enter t0 and t1 to zoom: ')\n",
    "\n",
    "ent = ent.rstrip().split(' ')\n",
    "t0 = float(ent[0])\n",
    "t1 = float(ent[1])\n",
    "#\n",
    "dt = gather[0].stats.starttime\n",
    "gather.plot(type='section',\n",
    "            scale=1.3, alpha=.7,\n",
    "            starttime=dt+t0, endtime=dt+t1,\n",
    "            orientation='horizontal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down-sample the data\n",
    "- Down-sample the data to number of pints compatible with the upper limit of the bandpass filter\n",
    "- Reduce computational costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "gather = gather0.copy()\n",
    "\"\"\"\n",
    "================= Downsample stream by an integer factor ======================\n",
    "\"\"\"\n",
    "print(f'\\n>> Phone {phone+1} has {gather[phone].stats.npts} data points with a sampling rate of {gather[phone].stats.sampling_rate}Hz,')\n",
    "dummy =  u.divisors(int(gather[phone].stats.sampling_rate), MTparam[4])\n",
    "print(f'    this sampling rate can be lowered to the following integer values {dummy}Hz')\n",
    "ent = input(f'\\n<< Enter a new sampling rate from the above list:')\n",
    "ent = float( ent.rstrip().split(' ')[0] )\n",
    "\"\"\"\n",
    "Decimate (other possiblity is resample)\n",
    "1) Only every decimation_factor-th sample remains in the trace.\n",
    "2) Prior to decimation it is applyed a lowpass filter to prevente aliasing artifacts.\n",
    "3) To abort when\n",
    "           len(data) % decimation_factor != 0\n",
    "    set strict_length=True.\n",
    "\"\"\"\n",
    "#--- // is a floor division = integer floor. Sanity\n",
    "factor = int(gather[phone].stats.sampling_rate / ent)\n",
    "if gather[phone].stats.npts % factor != 0: raise ValueError(\"Decimation factor is not an integer.\")\n",
    "gather.decimate(factor=factor, strict_length=True)\n",
    "#--- Check on Fmax\n",
    "MTparam[4] = MTparam[4] if MTparam[4] <= ent else ent\n",
    "#\n",
    "print(f'\\n>> Phone {phone+1} has now {gather[phone].stats.npts} data points with a new sampling rate of {gather[phone].stats.sampling_rate}Hz.')\n",
    "print(f'    Resampled data is FIR low-pass filtered to prevent aliasing, with a decimation factor of  {factor}.')\n",
    "#\n",
    "#------- Check frequency contents of a trace to accept downsampling\n",
    "#--- Relative time: nummpy array\n",
    "time = gather[phone].times(type=\"relative\")\n",
    "#--- Plot Trace+Spectrogram\n",
    "p.Pspect(time, gather[phone])\n",
    "#\n",
    "#------- Once filtering is accepted create a new backup for gather\n",
    "ent = input(f' Run this cell again (rtn= No)?: ') or False\n",
    "if not ent:\n",
    "    gather0 = gather.copy()\n",
    "    print(f' A new stream backup was created.')\n",
    "else:\n",
    "    gather = gather0.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## The direction-of-arrival (DOA). Choose an event with Beamforming\n",
    "- A wavefront arrives at the surface at an angle $i$ with the vertical. The wave propagates toward the surface with a velocity $v_{c}=\\frac{\\Delta s}{\\varDelta t}$, with a horizontal component $v_{h}=\\frac{\\Delta x}{\\varDelta t}$.\n",
    "\n",
    "- The horizontal slowness, $u_h$ is the inverse value of horizontal apparent velocity, $1/v_{h}$,\n",
    "$$\n",
    "u_{h}=\\frac{1}{v_{h}}=\\frac{\\sin i}{\\left|\\mathbf{v}_{c}\\right|},\n",
    "$$\n",
    "being related to: (a) the angle of incidence $i$, (b) the true velocity $v_c$ and (c) its azimuth with the North *toward* the epicenter; the **baz** ($\\theta$).\n",
    "$$\n",
    "\\boldsymbol{U}_0 = (\\frac{\\sin\\theta}{v_{h}},\\frac{\\cos\\theta}{v_{h}},\\frac{1}{v_{h}\\tan i})\n",
    "                 = \\frac{1}{v_{c}}(\\sin i\\sin\\theta,\\sin i\\cos\\theta,\\cos i)\n",
    "                 = u_{h}(\\sin\\theta,\\cos\\theta,\\frac{1}{\\tan i})\n",
    "                 = \\frac{1}{v_{c}}(\\sin i\\sin\\theta,\\sin i\\cos\\theta,\\cos i).\n",
    "$$\n",
    "\n",
    "- The seismic signals at each sensor can be time-shifted and summed to enhance the S/N ratio by a factor of $\\sqrt{N}$; the signals interfere constructively. The relative time shift of a given sensor $\\boldsymbol{r}_{i},\\,i=1,\\ldots,N$, relatively to the center of the array is \n",
    "$$\n",
    "\\tau_{i}=\\boldsymbol{r}_{i}.\\boldsymbol{u}.\n",
    "$$\n",
    "\n",
    "- The beamforming for the array is,\n",
    "$$\n",
    "\t\tb\\left(t\\right)=\\frac{1}{N}\\mathop{\\sum_{i=1}^{N}s_{i}\\left(t+\n",
    "\t\t\t\\mathbf{r}_{i}\\mathbf{\\cdot u}\\right)}=\\frac{1}{N}\\mathop{\\sum_{i=1}^{N}s_{i}\\left(t+\\tau_{i}\\right)}\n",
    "$$\n",
    "\n",
    "The ObsPy FK beamforming outputs the relative power, or semblance, and the absolute power, or FK power. Transforms the semblance $S$ to the Fisher or $F$-statistic as $F = (N-1) \\frac{S}{1-S}$. $F\\rightarrow1$ for white Gaussian noise, therefore if $F\\neq1$ means that there is some signal.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"./array1.png\" width=\"600\">\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================== BEAMFORMING ======================\n",
    "\"\"\"\n",
    "dummy = UTCDateTime()\n",
    "# ---------- Use FK Analysis\n",
    "out, stime, etime = u.BeamFK(gather, [MTparam[3], MTparam[4]], ttb_gloc)\n",
    "print(\"\\n>> Total time in Beamforming: %f\\n\" % (UTCDateTime() - dummy))\n",
    "#---------- Change output\n",
    "t, rel_power, abs_power, baz, slow = out.T\n",
    "#--- Time\n",
    "T = np.linspace(stime, etime, num=len(out))\n",
    "#--- Semblance -> Fisher\n",
    "F = (len(gather)-1) * out[:, 1] / (1 - out[:, 1])\n",
    "#--- FK power\n",
    "FKp = out[:, 2]\n",
    "#--- baz\n",
    "#out[:, 3] = out[:, 3] % 360.\n",
    "baz = baz % 360.\n",
    "#--- Slowness -> Velocity\n",
    "V = 1.e3 / out[:,4]\n",
    "#------------- print\n",
    "sys.stdout.write('\\n')\n",
    "print(f'\\n>>  t   Fisher  FKpwr   baz(deg) vel(m/s)')    \n",
    "for i in range(len(out)):\n",
    "    print(f'   {round(T[i],2)}, {round(F[i],2)}, {round(FKp[i],2)}, {round(baz[i],2)}, {round(V[i],2)}')    \n",
    "#------------ Plot\n",
    "p.pltbaz(out, stime , etime)\n",
    "\"\"\"\n",
    "1) CLICK ON BLUE BAR TO EXPAND\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is this velocity expected to be real?\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"./rockVel.png\" width=\"500\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ---------- Pairwise distances between points ----------\n",
    "\"\"\"\n",
    "  <Args>\n",
    "    matrix -> A 3-column matrix: [[phone, x, y], ...] (x, y = cartesian coordinates)\n",
    "    ainc   -> An angle increment\n",
    "  <Returns>\n",
    "    maxdist -> A 4-column matrix: [[phone1, phone2, dist,  angle], ...]\n",
    "                                      int     int   float  float\n",
    "                    angle -> (degrees) polar angle\n",
    "                    dist  -> distance between phone1 and phone2)\n",
    "                    maxdist is filtered by the largest distance near a given angle\n",
    "\n",
    "\"\"\"\n",
    "def pairs(matrix, angle_increment):\n",
    "#\n",
    "#------  Convert to numpy array if necessary\n",
    "    if not isinstance(matrix, np.ndarray):\n",
    "        matrix = np.array(matrix)\n",
    "#\n",
    "#------  Calculate the baricenter\n",
    "    baricenter_x = np.mean(matrix[:, 1])\n",
    "    baricenter_y = np.mean(matrix[:, 2])\n",
    "#\n",
    "#------ Create an empty list to store results\n",
    "    results = []\n",
    "#\n",
    "#------ Iterate through angles \n",
    "    for angle in range(0, 180, angle_increment):\n",
    "      # Convert angle to radians\n",
    "        rad = np.radians(angle)\n",
    "        # Define the diameter\n",
    "        diameter_slope = np.tan(rad)\n",
    "#\n",
    "#------  Find the pair of points with minimum distance from the current diameter\n",
    "        min_distance = float('inf')\n",
    "        point1_index = -1\n",
    "        point2_index = -1\n",
    "        for i in range(len(matrix)):\n",
    "            for j in range(i + 1, len(matrix)):\n",
    "                # Calculate distance from the line\n",
    "                dist_i = abs((matrix[i, 2] - baricenter_y) - diameter_slope * (matrix[i, 1] - baricenter_x)) / (np.sqrt(1 + diameter_slope**2))\n",
    "                dist_j = abs((matrix[j, 2] - baricenter_y) - diameter_slope * (matrix[j, 1] - baricenter_x)) / (np.sqrt(1 + diameter_slope**2))\n",
    "                total_dist = dist_i + dist_j\n",
    "\n",
    "                if total_dist < min_distance:\n",
    "                    \n",
    "                   # print(point1_index,point2_index,total_dist,min_distance)\n",
    "                    \n",
    "                    min_distance = total_dist\n",
    "                    point1_index = int(matrix[i,0])\n",
    "                    point2_index = int(matrix[j,0])\n",
    "#\n",
    "#------ Calculate distance between the selected pair\n",
    "        distance = np.sqrt((matrix[int(np.where(matrix[:,0] == point1_index)[0]), 1] - matrix[int(np.where(matrix[:,0] == point2_index)[0]), 1])**2 + (matrix[int(np.where(matrix[:,0] == point1_index)[0]), 2] - matrix[int(np.where(matrix[:,0] == point2_index)[0]), 2])**2)\n",
    "#\n",
    "#------ Angle relative to vertical axis\n",
    "        results.append([int(point1_index), int(point2_index), distance, angle])  #90. - angle\n",
    "    return np.array(results, dtype=object)\n",
    "#\n",
    "# -------------- End of function   ---------------------\n",
    "print(f'\\n>> Functions loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Choose phone pairs\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"./ttbg.png\" width=\"500\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================== Phone pairs ======================\n",
    "\"\"\"\n",
    "print(f'\\n>> Choose pairs of the {len(gather)} using the polar angle of a rotating diameter.')\n",
    "ent = input(f'\\n<< Enter an angle step (rtn = 20 deg.):') or '20'\n",
    "ent = int( ent.rstrip().split(' ')[0] )\n",
    "matrix = pairs(ttb_loc, ent)\n",
    "print(f'ph1|ph2|     distance(m)    |angle(deg.)|')\n",
    "for row in matrix:\n",
    "    print(\" | \".join(map(str, row)))\n",
    "#\n",
    "#------ Choose a single pair\n",
    "ent = input(f'\\n<< Enter the 1st phone from above table:')\n",
    "ent = int( ent.rstrip().split(' ')[0] )\n",
    "i = next((i for i, row in enumerate(matrix) if row[0] == ent), -1)\n",
    "print(f'\\n>> Work with the pair [{matrix[i,0]}, {matrix[i,1]}], with a distance of {round(matrix[i,2],2)}m')\n",
    "#\n",
    "#------ Create an empty stream add the two traces\n",
    "distance = matrix[i,2]\n",
    "ntr1, ntr2 = matrix[i,:2] - 1\n",
    "st = Stream()\n",
    "st += gather[ntr1].copy()\n",
    "st += gather[ntr2].copy()\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization and Spectral whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================== Trace normalization and spectral whitening ======================\n",
    "\"\"\"\n",
    "dt   = st[0].stats.delta               # sampling interval\n",
    "fNy  = 1. / (2.0 * dt)                    # Nyquist frequency\n",
    "#- time = st[ntr1].times(type=\"relative\")\n",
    "#\n",
    "#------ Normalize and whiten\n",
    "for tr in st:\n",
    "#--- Taper the data with 10% Hanning\n",
    "    tr.taper(type = 'hann', max_percentage = 0.1)\n",
    "#--- Time normalization == 'one_bit' -> sign normalization\n",
    "    tr = np.sign(tr)\n",
    "#--- Whiten\n",
    "#    tr = u.whiten(tr, MTparam[3], MTparam[4])\n",
    "#    trw = whiten(tr, delta = dt, freqmin = MTparam[3], freqmax = MTparam[4], smooth_N  = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambient Noise Cross-correlation\n",
    "- Given two seismometers, $u_1$ and $u_2$, on the surface, will record ground motion as a function of time. Over long periods of time, the cross-correlation of ground motions is\n",
    "$$C_{1,2}\\left(\\tau\\right)=\\int u_{1}\\left(t\\right)\\,u_{2}\\left(t+\\tau\\right)dt$$\n",
    "\n",
    "- Data Preparation and inital processing\n",
    "Prepare waveform data from each station separately to accentuate broad-band ambient noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================== Trace correlation ======================\n",
    "\"\"\"\n",
    "print(f'\\n>> Correlate trace {ntr1} with {st[0].stats.npts} with trace {ntr2} with {st[1].stats.npts} points')\n",
    "ent = input(f'\\n<< Enter max lag time (rtn = 2s):') or '2'\n",
    "ent = float( ent.rstrip().split(' ')[0] )\n",
    "max_lagtime = ent\n",
    "#\n",
    "max_shift_num = int(np.round(max_lagtime*st[0].stats.sampling_rate))\n",
    "data1 = st[0].data\n",
    "data2 = st[1].data\n",
    "len1 = len(data1)\n",
    "len2 = len(data2)\n",
    "min_len = min(len1,len2)\n",
    "#\n",
    "cross_list = []\n",
    "for shift_num in np.arange(-max_shift_num,max_shift_num+1,1):\n",
    "    if shift_num<0:\n",
    "        correlate_value = np.correlate(data1[:min_len+shift_num],data2[-shift_num:min_len])\n",
    "        cross_list.append(correlate_value.ravel())\n",
    "    else:\n",
    "        correlate_value = np.correlate(data2[:min_len-shift_num],data1[shift_num:min_len])\n",
    "        cross_list.append(correlate_value.ravel())\n",
    "cross_list = np.array(cross_list)\n",
    "cross_list = cross_list/np.max(cross_list)\n",
    "#\n",
    "fs_new = st[0].stats.sampling_rate\n",
    "time = np.linspace(-max_lagtime,max_lagtime,int(2*max_lagtime*fs_new+1))\n",
    "#-------- \n",
    "indexmax = np.argmax(cross_list)\n",
    "travtime = time[indexmax]\n",
    "print(f'\\n>> Maximum lag = {travtime}s, corresponding to a velocity {np.round(distance/travtime, 2)}m/s')\n",
    "#\n",
    "plt.figure(figsize=(6, 2), dpi=180)\n",
    "plt.plot(time,cross_list, 'k-')\n",
    "#plt.plot(time, envelope, 'r-')\n",
    "plt.axvline(travtime, 0.85, 1, color='b', lw=3)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"X-cor Coeff\")\n",
    "plt.xlim(-max_lagtime,max_lagtime)\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
