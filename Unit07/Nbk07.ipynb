{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeMSvOAPfX5S"
   },
   "source": [
    "---\n",
    "# Unit07: The Network and Array Methods\n",
    "\n",
    "This notebook has the activities of the Course **ProSeisSN**. It deals with time series processing using a passive seismic dataset using [ObsPy](https://docs.obspy.org/).\n",
    "\n",
    "#### Dependencies: Obspy, Numpy, Matplotlib\n",
    "#### Reset the Jupyter/IPython notebook in order to run it again, press:\n",
    "***Kernel*** -> ***Restart & Clear Output***\n",
    "#### The code $\\Downarrow$ BELOW $\\Downarrow$ runs a notebook with other dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "uzMJ-lGlkGuK",
    "outputId": "66c27f9e-fd21-4a54-ed6d-6a23b77ec540",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#------ Import Libraries\n",
    "import sys\n",
    "import os\n",
    "    \n",
    "#------ Work with the directory structure to include auxiliary codes\n",
    "print('\\n Local directory ==> ', os.getcwd())\n",
    "print('  - Contents: ', os.listdir(), '\\n')\n",
    "\n",
    "path = os.path.abspath(os.path.join('..'))\n",
    "if path not in sys.path:\n",
    "    sys.path.append(path+\"/CodePy\")\n",
    "\n",
    "%run ../CodePy/ImpMod.ipynb\n",
    "\n",
    "#------ Alter default matplotlib rcParams\n",
    "from matplotlib import rcParams\n",
    "# Change the defaults of the runtime configuration settings in the global variable matplotlib.rcParams\n",
    "plt.rcParams['figure.figsize'] = 9, 5\n",
    "#plt.rcParams['lines.linewidth'] = 0.5\n",
    "plt.rcParams[\"figure.subplot.hspace\"] = (.9)\n",
    "\n",
    "#------ Magic commands\n",
    "%matplotlib inline\n",
    "%matplotlib widget\n",
    "#%pylab notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UQ66x8GfX5U"
   },
   "source": [
    "---\n",
    "## Read a data set from TTB22\n",
    "As ondas sísmicas geradas pela transferência da energia do fluxo turbulento no estuário do Rio Amazonas, resultante das suas grandes marés, por forças friccionais às rugosidades do seu fundo. O arranjo sísmico foi instalado na Ilha de Tatuoca, como tal o arranjo está circundado por uma distribuição de fontes no leito do rio. Fontes e geofones estão na superfície, tornando as ondas de superfície francamente dominantes em relação às de volume.\n",
    "### The Experiment\n",
    "- **The Receiver Array**\n",
    "The array has 24 GS-20DX vertical geophones hooked to a $L=69$m cable, using takeouts spaced $\\delta l=6$m from each other. The GS-20DX geophones have a natural frequency of $f_n=10\\textrm{Hz}$, and a spurious frequency $f_{sp}>250$Hz. The array has a irregular circular shape, deployed in the Southern tip of the island, with its center at $\\left(1^{\\circ}12^{\\prime}6.93^{\\prime\\prime}\\textrm{S},48^{\\circ}30^{\\prime}23.39^{\\prime\\prime}\\textrm{S}\\right)$.\n",
    "\n",
    "<img src=\"./ttb22.png\" width=\"600\">\n",
    "\n",
    "- **The data**\n",
    "Each of the 12 traces of **file 3804** is $\\Delta T=60$s long, with a sampling frequency of $f_{s}=250$Hz. This file was recorded on 2022-04-02, begining at 13h 56min 41s. That was during the maximum gradient of the local ebb tide.\n",
    "\n",
    "<img src=\"./tide.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================== A local routine to read a CSV file ======================\n",
    "Read a cvs file and stores the information in an object numpy array\n",
    "\"\"\"\n",
    "def RGloc(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            data = []\n",
    "            for line in lines[1:]:               # Skip header row\n",
    "                parts = line.strip().split(',')\n",
    "                data.append([int(parts[0]), float(parts[1]), float(parts[2])])\n",
    "        return np.array(data, dtype=object)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{filename}' not found.\")\n",
    "        return None                                 \n",
    "#\n",
    "\"\"\"\n",
    "====================== READ THE SEISMIC DATA LOCALLY ======================\n",
    "\"\"\"\n",
    "#\n",
    "#------ Read the seismic data\n",
    "filename = '3804'\n",
    "print(f\">> Read with data file {filename}\")\n",
    "filename = '../Data/'+filename+'.dat'   \n",
    "#------- Read the data file as a SEG2 object\n",
    "st = read(filename)\n",
    "#\n",
    "#------- Print stream information\n",
    "dummy = float(st[-1].stats.seg2.RECEIVER_LOCATION)\n",
    "print(f\"1) Gather acquired on {st[0].stats.starttime}, has {len(st)} geophones along {dummy}m.\")\n",
    "dummy = (UTCDateTime(st[0].stats.endtime) - UTCDateTime(st[0].stats.starttime))\n",
    "print(f\"2) Each {dummy}s-long trace has {int(st[0].stats.npts)} data points.\")\n",
    "print(f\"3) The sampling frequency is {st[0].stats.sampling_rate}Hz\")\n",
    "#\n",
    "\"\"\"\n",
    "====================== READ THE PHONES LOCATIONS ======================\n",
    "\"\"\"\n",
    "#------ Read the phones cartesian locations\n",
    "#--- Reads the CSV file with (x, y)m locations\n",
    "ttb_loc = RGloc('../Data/'+'ttb_loc.dat')\n",
    "#\n",
    "#------ Read the phones geographic locations\n",
    "#--- Reads the CSV file with (lat,lon) in degress locations\n",
    "ttb_gloc = RGloc('../Data/'+'ttb_gloc.dat')\n",
    "#\n",
    "#------ Plot gather in cartesian\n",
    "p.pgather(ttb_loc[:,1], ttb_loc[:,2], ttb_loc[:,0], coord='cartesian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Have a look at one trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ Pick up a phone\n",
    "dummy = np.random.randint(1, len(st)+1)\n",
    "ent = input(f' Enter a phone [dflt=random] ')\n",
    "ent = int( ent.rstrip().split(' ')[0] ) if ent else dummy\n",
    "#------- The trace\n",
    "trZ = st[ent - 1].copy()\n",
    "#       +───────+─> Trace = Phone -1 \n",
    "#------- Deep copy of the trace\n",
    "tr0 = trZ.copy()\n",
    "#------ Relative time: nummpy array\n",
    "time = trZ.times(type=\"relative\")\n",
    "#------- Filter the trace\n",
    "#--- Filter parameters\n",
    "MTparam = [1, 1, 'bp',  5., 50., 1, 0]\n",
    "# └─────> [dtr, line, ftype, Fmin, Fmax, taper, gain]\n",
    "trZ = u.otrstr(trZ, MTparam)\n",
    "#------ Plot Spectrogram\n",
    "p.Pspect(time, trZ)\n",
    "#\n",
    "#-------- Save trace for the next cell + append to the processing flux\n",
    "tr0, trZ, _ = u.AuxReset(tr0, trZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Detect events with the trigger algorithms\n",
    "- The STA window length $\\Delta T_{STA}$ measures the average amplitude of the seismic **signals**.\n",
    "- The LTA window length $\\Delta T_{LTA}$, measures the average amplitude of the seismic **noise**, with lengths **larger** than a few periods of noise fluctuations.\n",
    "- The relative occurences of **positive**, **false positive** and **missed positive** is conditioned by the STA/LTA trigger threshold level $\\mathcal{T}_{STA/LTA}$.\n",
    "- The termination of data recording is estimated with the STA/LTA detrigger threshold level $\\widetilde{\\mathcal{T}}_{STA/LTA}$.\n",
    "\n",
    "$\\mathcal{A}\\left(s+n\\right)\\rightarrow0$ | $\\mathcal{A}\\left(s+n\\right)\\rightarrow\\infty$ |$\\qquad\\mathcal{T}_{STA/LTA}\\rightarrow0$ | $\\qquad\\mathcal{T}_{STA/LTA}\\rightarrow\\infty$ |\n",
    "| :- | :- | :- | :- |\n",
    "| $\\mathcal{T}_{STA/LTA}\\approx4$ | $\\mathcal{T}_{STA/LTA}\\gtrsim8$ | $\\textrm{events}+\\textrm{false-trigg.}\\rightarrow\\infty$ | $\\textrm{misses}\\rightarrow\\infty,\\,\\textrm{false-trigg.}\\rightarrow 0$ |\n",
    "| $\\widetilde{\\mathcal{T}}_{STA/LTA}\\approx2-3$ | $\\widetilde{\\mathcal{T}}_{STA/LTA}>3$ | stationary seismic noise | irregular seismic noise levels|\n",
    "\n",
    "<img src=\"StaLta2.png\" width=\"500\">\n",
    "\n",
    "### STA/LTA recursive detector\n",
    "- Work with a single trace.\n",
    "- Try different STA and LTA lengths. Rule of thumb $\\rightarrow$ is that $\\Delta T_{STA}\\approx\\textrm{signal}$ **and** $\\Delta T_{LTA}\\gg\\lambda_{\\textrm{low freq. noise}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ Import Packages\n",
    "from obspy.signal.trigger import plot_trigger\n",
    "from obspy.signal.trigger import recursive_sta_lta\n",
    "#\n",
    "print(f\">> Trigger packages imported.\")\n",
    "\n",
    "\"\"\"\n",
    "Parameters:\n",
    "nsta(int) – Length of short time average window in samples\n",
    "nlta(int) – Length of long time average window in samples\n",
    "\"\"\"\n",
    "print(f\">> Sampling interval = {np.round(trZ.stats.delta, 5)}s\")\n",
    "#\n",
    "#------ Enter STA and LTA in s.\n",
    "ent = input(f'<< Enter STA and LTA in s: ')\n",
    "ent = ent.rstrip().split(' ')\n",
    "sta = float(ent[0])\n",
    "lta = float(ent[1])\n",
    "#\n",
    "dummy = sta\n",
    "sta = int(sta * trZ.stats.sampling_rate)\n",
    "print(f\">> sta = {dummy}s or {sta} data points\")\n",
    "#\n",
    "dummy = lta\n",
    "lta = int(lta * trZ.stats.sampling_rate)\n",
    "print(f\">> lta = {dummy}s or {lta} data points\")\n",
    "#\n",
    "#------ Enter trigger and detrigger thresholds.\n",
    "ent = input(f'<< Enter trigger and detrigger thresholds: ')\n",
    "ent = ent.rstrip().split(' ')\n",
    "trg  = float(ent[0])\n",
    "dtrg = float(ent[1])\n",
    "#\n",
    "#------ Hints: STA, LTA = 0.5 5;  trigger, detrigger thresholds = 2 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Recursive STA/LTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ STA and LTA hints: 5 10\n",
    "#------ Trigger and detrigger hints: 1.5 0.5\n",
    "cft = recursive_sta_lta(trZ.data, sta, lta)\n",
    "#\n",
    "plot_trigger(trZ, cft, trg, dtrg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Matched-filter detection\n",
    "The seismogram suggests river generated signals have similar waveforms, a similarity that could be used for detection. Based on this we can use the correlation between a **template waveform** and the data to generate a characteristic function, and with it, detect events. The pros of correlation detectors are:\n",
    "- They can potentially detect lower S/N events;\n",
    "- They do not require amplitudes to return to low levels, so close in time multiple events are more likely to be detected.\n",
    "\n",
    "Conversely their cons are that they need a **template**, implying a restriction to events close in space and with similar focal mechanisms.\n",
    "\n",
    "A tutorial in ObsPy can be found at [here](https://docs.obspy.org/master/tutorial/code_snippets/xcorr_detector.html), and a package on the subject is at [EQcorrscan](https://github.com/eqcorrscan/EQcorrscan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ Plot Trace+Spectrogram\n",
    "p.Pspect(time, trZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a catalog of templates. \n",
    "\"\"\"\n",
    "cat = []\n",
    "while True:\n",
    "  trTplt = trZ.copy()\n",
    "  ent = input(f'<< Enter pck0 and pck1 in s (rtn=exit): ')\n",
    "  if not ent: break\n",
    "  ent = ent.rstrip().split(' ')\n",
    "  pck0 = trTplt.stats.starttime + float(ent[0])\n",
    "  pck1 = trTplt.stats.starttime + float(ent[1])\n",
    "#------ Trim the template\n",
    "  trTplt.trim(pck0, pck1)\n",
    "  print(f\">> Template is at [{pck0}, {pck1}] with {len(trTplt)} data points.\")\n",
    "#------ Relative time: nummpy array\n",
    "  dummy = trTplt.times(type=\"relative\")\n",
    "#------ fft\n",
    "  fNy = 0.8 * trTplt.stats.sampling_rate / 2.\n",
    "  FtrTplt = np.fft.rfft(trTplt.data)\n",
    "  freq = np.linspace(0, fNy, len(FtrTplt))\n",
    "  p.pltTrSp( dummy, trTplt.data, freq, abs(FtrTplt),\n",
    "              x1label='s', y1label='Ampl.', y1log=False, clr1 = 'k', \n",
    "              x2label='Hz', y2label='Spec.', y2log=True, clr2 = 'r' )\n",
    "#------ Construct catalog\n",
    "  cat.append(trTplt)   \n",
    "#------ The catalog\n",
    "trTplt = cat\n",
    "print(f\">> Template catalog has {len(trTplt)} templates.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Detect events with the Matched-filter detection algorithms\n",
    "Work with a single trace. It is necessary to provide two paramters:\n",
    "- The correlation threshold within the normalised correlation range [-1, 1]\n",
    "- The triger off time in s. This is the minimum distance between events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ Import Packages\n",
    "from obspy.signal.cross_correlation import correlation_detector\n",
    "import pprint\n",
    "print(f\">> Trigger packages imported.\")\n",
    "#\n",
    "#------ Enter height and distance. Hint: .6 2\n",
    "ent = input(f'<< Enter correlation threshold and triger off time(s): ')\n",
    "ent = ent.rstrip().split(' ')\n",
    "corthr   = float(ent[0])\n",
    "trgoff   = float(ent[1])\n",
    "#\n",
    "#------ Produce ObsPy stream\n",
    "stream  = Stream([trZ])\n",
    "#tmplstr = [Stream([template]) for template in trTplt]\n",
    "#tmplstr = Stream([trTplt])\n",
    "#\n",
    "#------ Detections. Free memory on each loop.\n",
    "detect = []\n",
    "for template in trTplt:\n",
    "    tmplstr = Stream([template])\n",
    "    dets, sims = correlation_detector(\n",
    "                   stream=stream, templates=[tmplstr],\n",
    "                   heights=corthr, distance=trgoff, plot=stream)\n",
    "    detect.extend(dets)\n",
    "#\n",
    "print(\"Made {0} detections from {1} templates\".format(\n",
    "    len(detect), len(trTplt)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
