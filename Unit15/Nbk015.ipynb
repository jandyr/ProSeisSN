{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeMSvOAPfX5S"
   },
   "source": [
    "##### ---\n",
    "# Unit15: Ambient Noise Tomography\n",
    "\n",
    "This notebook has the activities of the Course **ProSeisSN**. It deals with time series processing using a passive seismic dataset using [ObsPy](https://docs.obspy.org/).\n",
    "\n",
    "#### Dependencies: Obspy, Numpy, Matplotlib\n",
    "#### Reset the Jupyter notebook in order to run it again, press:\n",
    "***Kernel*** -> ***Restart & Clear Output***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================== Leads to Colab ======================\n",
    "1)\n",
    "!git clone https://github.com/jandyr/ProSeisSN\n",
    "!cd ProSeisSN\n",
    "2)\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "subprocess.check_call(['install', 'obspy'])\n",
    "print(f\"obspy installed successfully using conda.\")\n",
    "return True\n",
    "except subprocess.CalledProcessError:\n",
    "print(f\"Failed to install obspy using conda. Trying pip.\")\n",
    "    try:\n",
    "      subprocess.check_call(['pip', 'install', 'obspy'])\n",
    "      print(f\"'obspy' installed successfully using pip.\")\n",
    "      return True\n",
    "    except subprocess.CalledProcessError:\n",
    "      print(f\"Failed to install {package_name} using both pip and apt-get.\")\n",
    "      return False\n",
    "\"\"\"\n",
    "#!pip install pycwt\n",
    "#import pycwt\n",
    "!pip install disba mpi_master_slave\n",
    "!pip install pylops\n",
    "#!pip install obspy\n",
    "!pip install import-ipynb\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "uzMJ-lGlkGuK",
    "outputId": "66c27f9e-fd21-4a54-ed6d-6a23b77ec540",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#------ Import OS Libraries\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#------ Work with the directory structure to include auxiliary codes\n",
    "print('\\n Local directory ==> ', os.getcwd())\n",
    "print('  - Contents: ', os.listdir(), '\\n')\n",
    "\n",
    "path = os.path.abspath(os.path.join('..'))\n",
    "if path not in sys.path:\n",
    "    sys.path.append(path+\"/CodePy\")\n",
    "\n",
    "#%run ../CodePy/ImpMod.ipynb\n",
    "%run ../CodePy/ImpMod\n",
    "#------ Alter default matplotlib rcParams\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.dates as dates\n",
    "# Change the defaults of the runtime configuration settings in the global variable matplotlib.rcParams\n",
    "plt.rcParams['figure.figsize'] = 9, 5\n",
    "#plt.rcParams['lines.linewidth'] = 0.5\n",
    "plt.rcParams[\"figure.subplot.hspace\"] = (.9)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "#------ Magic commands\n",
    "%matplotlib inline\n",
    "%matplotlib widget\n",
    "#%pylab notebook\n",
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## The 84S Dataset\n",
    "- **The context**\n",
    "  1) The seismic source is ambient noise generated by the energy transfer from the winds on features on the snow surface and the Cryosphere-I.\n",
    "  2) Two 66m gathers with 12 geophones each. Each trace has a time window ùõøùë° = 8s and a sampling rate ùõøùëì = 2000Hz,\n",
    "resulting in 16000 data points/trace. We focus here on the first gather.\n",
    "  3) Geophone location along profile due S from Crios-I: D1 = 200m, D2 = 40m, G1 = G2 = 66m\n",
    "  \n",
    " ‚îÇCrios‚îÇ D1 ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ G1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ| D2 ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ G2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ| \n",
    " \n",
    "            o o o o o o o o o o o o<-->o o o o o o o o o o o o \n",
    "\n",
    "  4) Files 4600 and 4608 were collected in a day with a strong breeze, wind force 6 on the Beaufort Scale, with gusts reaching 12ùëö/ùë†. The data is notched at 60.62Hz as well as its even harmonics up to 606.2Hz.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"./84S.png\" width=\"800\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================== READ PHONES LOCATIONS ======================\n",
    "\"\"\"\n",
    "#------ Read the phones cartesian locations\n",
    "#--- Reads the CSV file with (x, y)m locations\n",
    "loc84S = u.RGloc('../Data/'+'84S_loc.dat')\n",
    "#------ Read the phones geographic locations\n",
    "#--- Reads the CSV file with (lat,lon). All (0., 0.)!\n",
    "gloc84S = u.RGloc('../Data/'+'84S_gloc.dat')\n",
    "#\n",
    "#------ Plot gather in cartesian\n",
    "p.pgather(loc84S[:,1], loc84S[:,2], loc84S[:,0], coord='cartesian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================== READ THE SEISMIC DATA LOCALLY ======================\n",
    "File hints: 4600, 4608\n",
    "\n",
    "\"\"\"\n",
    "#------ Read the seismic data\n",
    "ent = str(np.random.choice(np.arange(3700, 3811, 10)))\n",
    "ent = input(f'   Enter a file number in [4600 or 4608], rtn=4600:\\n') or '4600'\n",
    "ent = ent.rstrip().split(' ')\n",
    "print(f\">> Read with data file {ent}\")\n",
    "ent = '../Data/84S/'+ent[0]+'.dat'\n",
    "#------- Read the data file as a SEG2 object.\n",
    "st     = read(ent)\n",
    "#\n",
    "#------- Print stream information\n",
    "dummy = float(st[-1].stats.seg2.RECEIVER_LOCATION)\n",
    "print(f\">> Gather acquired on {st[0].stats.starttime}, has {int(st[0].stats.npts)} data points.\")\n",
    "\"\"\"\n",
    "================= Create a new stream from the SEG2 stream ======================\n",
    "                         Retain a gather copy\n",
    "\"\"\"\n",
    "#------ Create a new stream from the SEG2 stream.\n",
    "#       1) Adds coordinates to gather. Stores a copy in gather0\n",
    "#       2) Gather baricenter = bcenter.\n",
    "gather, bcenter = u.creastrm(st, gloc84S, hght = 2000., surv = '84S')\n",
    "gather0 = gather.copy()\n",
    "#\n",
    "#--- Phone choice\n",
    "phone = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data processing\n",
    "- Filter data\n",
    "- Display the seismogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\"\"\"\n",
    "================= Filter data and look at the frequency contents ======================\n",
    "                    Create a new stream from the SEG2 stream\n",
    "\"\"\"\n",
    "#\n",
    "#------- Remove mean and trend + filter the stream\n",
    "#--- Filter parameters: change them as you wish.\n",
    "MTparam = [ 1,   1,    'bp',  10.,   40.,   0,    0]\n",
    "# ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> [dtr, line, ftype, Fmin, Fmax, taper, gain]\n",
    "#                                          ‚îî‚îÄ> data will be windowed at trace normalization and spectral whitening\n",
    "ent = str(MTparam[3]) + ' ' + str(MTparam[4])\n",
    "ent = input(f'\\n Enter filter min and max frequencies (dflt = {MTparam[3]}, {MTparam[4]})') or ent\n",
    "ent = ent.rstrip().split(' ')\n",
    "MTparam[3], MTparam[4] = [float(dummy) for dummy in ent]\n",
    "#\n",
    "gather = u.otrstr(gather, MTparam)\n",
    "#\n",
    "#------- Check frequency contents to accept preprocessing\n",
    "#--- Pick up a random phone/trace\n",
    "phone = phone if phone is not None else np.random.randint(1, len(gather)+1)\n",
    "print(f' Random phone {phone} ')\n",
    "#--- Go to trace instead of phone: trace = phone -1\n",
    "phone = phone - 1\n",
    "#--- Relative time: nummpy array\n",
    "time = gather[phone].times(type=\"relative\")\n",
    "#--- Plot Trace+Spectrogram\n",
    "p.Pspect(time, gather[phone])\n",
    "#\n",
    "#------- Once filtering is accepted create a new backup for gather\n",
    "ent = input(f' Run this cell again (rtn= No, else plot Spectrogram)?: ') or False\n",
    "if not ent:\n",
    "    gather0 = gather.copy()\n",
    "    print(f' A new stream backup was created.')\n",
    "else:\n",
    "    gather = gather0.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down-sample the data\n",
    "- Down-sample the data to number of pints compatible with the upper limit of the bandpass filter\n",
    "- Reduce computational costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "#\n",
    "gather = gather0.copy()\n",
    "\"\"\"\n",
    "================= Downsample stream by an integer factor ======================\n",
    "\"\"\"\n",
    "print(f'\\n>> Phone {phone+1} has {gather[phone].stats.npts} data points with a sampling rate of {gather[phone].stats.sampling_rate}Hz,')\n",
    "#--- Divisors of sampling rate > upper frequency bound of the band-pass filter above\n",
    "dummy =  u.divisors(int(gather[phone].stats.sampling_rate), MTparam[4])\n",
    "#--- Find the decimation/resampling factors\n",
    "factor = [math.trunc(gather[phone].stats.sampling_rate / num) for num in dummy]\n",
    "factor = [factor for factor in factor if factor < 16]\n",
    "#\n",
    "dummy =  [int(gather[phone].stats.sampling_rate/factor) for factor in factor]\n",
    "print(f'    this sampling rate can be lowered to the following integer values {dummy}Hz')\n",
    "print(f'    representing decimation factors of............................... {factor},')\n",
    "dummy = [math.trunc(gather[phone].stats.npts / factor) for factor in factor]\n",
    "print(f'    with a total of points of ....................................... {dummy},')\n",
    "#\n",
    "print(f'\\n>> If you need a higher decimation factor than {factor[0]}:')\n",
    "print(f'    1) Set a value from the above, and accept the running;')\n",
    "print(f'    2) Run the cell again with a new factor to your goal.')\n",
    "#\n",
    "print(f'\\n>> Note that data is already band pass filtered in the range [{MTparam[3]}, {MTparam[4]}]Hz.')\n",
    "print(f'    Be sure decimation is above the upper limit')\n",
    "#\n",
    "ent = input(f'\\n<< Enter a new sampling rate from the above list:')\n",
    "ent = float( ent.rstrip().split(' ')[0] )\n",
    "#--- Check on Fmax\n",
    "#MTparam[4] = MTparam[4] if MTparam[4] <= ent else ent\n",
    "#\n",
    "#------- Check on decimation factor. // is a floor division = integer floor.\n",
    "factor = int(gather[phone].stats.sampling_rate / ent)\n",
    "if gather[phone].stats.npts % factor != 0: raise ValueError(\"Decimation factor is not an integer.\")\n",
    "\"\"\"\n",
    "Decimate or resample\n",
    "1) Use resample instead of decimate if factor >16, as automatic filter design becomes unstable.\n",
    "2) After decimation every n-th sample remains in the trace.\n",
    "3) Prior to decimation it is applyed a lowpass filter to prevente aliasing artifacts.\n",
    "4) If decimation factor is too large the FFT will fold itself in two, with a middle spike within its frequency range.\n",
    "\"\"\"\n",
    "print(factor)\n",
    "if factor <= 15:\n",
    "    gather.decimate(factor=factor)                        #Uses: no_filter=False, strict_length=False\n",
    "    print(f'\\n>> Decimation factor is {factor} -> use decimate.')\n",
    "else:\n",
    "    gather.resample(ent, window='hann', no_filter=False)  #Uses: strict_length=False\n",
    "    print(f'\\n>> Decimation factor is {factor} -> use resample.')\n",
    "#\n",
    "print(f'>> Phone {phone+1} has now {gather[phone].stats.npts} data points with a new sampling rate of {gather[phone].stats.sampling_rate}Hz.')\n",
    "print(f'    Resampled data is low-pass filtered to prevent aliasing, with a decimation factor of  {factor}.')\n",
    "#\n",
    "#------- Check frequency contents of a trace to accept downsampling\n",
    "#--- Relative time: nummpy array\n",
    "time = gather[phone].times(type=\"relative\")\n",
    "#--- Plot Trace+Spectrogram\n",
    "p.Pspect(time, gather[phone])\n",
    "#\n",
    "#------- Once filtering is accepted create a new backup for gather\n",
    "ent = input(f' Run this cell again (rtn= No)?: ') or False\n",
    "if not ent:\n",
    "    gather0 = gather.copy()\n",
    "    print(f' A new stream backup was created.')\n",
    "else:\n",
    "    gather = gather0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================== Plot Seismogram ======================\n",
    "\"\"\"\n",
    "gather.plot(type='section',\n",
    "            scale=1.3, alpha=.7,\n",
    "            orientation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Normalization and Spectral whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================== Trace normalization and spectral whitening ======================\n",
    "1) Cross-correlations are estimated in receiver pairs, where one is concidered as a source:\n",
    "-> BEFORE CROSS-CORRELATION IT IS NECESSARY TO TAKE THE CONJUGATE OF THE SOURCE TRACE\n",
    "                            trS = np.conjugate(trS)\n",
    "    SO THE SOURCE SPETRUM IS CONSISTENT WITH THE RECEIVER.\n",
    "2) The O/P of 'noise_processing', tr0W, will be next_fast_len(len(FtrTplt)) greater than len(FtrTplt)\n",
    "3) We are not discarding the first element of the FFT output, or its DC energy as we have already detrended and demeaned the data.\n",
    "\"\"\"\n",
    "#\n",
    "#------ Initialization\n",
    "st = Stream()\n",
    "nwGather = np.zeros((len(gather[0]), len(gather)))\n",
    "#\n",
    "#------ Loop through traces:\n",
    "#       1) Append each processed spectrum as a new column into a new 2-D array\n",
    "#       2) Create a new stream with the inverse FFT.\n",
    "#\n",
    "for i, t in enumerate(gather):\n",
    "#--- Build the processed freq. domain data: nwGather[data, trace]\n",
    "    tr0W = u.noise_processing(t.data, t.stats.delta, MTparam[3], MTparam[4], \n",
    "                              smooth_N = 100, time_norm = 'one_bit', freq_norm = 'rma')\n",
    "    nwGather[:, i] = tr0W\n",
    "#--- Inverse fourier transform of the whitened spectra (not tapered)\n",
    "    trw = np.fft.ifft(tr0W)\n",
    "#--- Discard small complex values left-overs after the inverse fourier transform\n",
    "    trw = np.real(trw)\n",
    "#--- Build the trace. Distance is along cable, NOT from Crios-I\n",
    "    trw = Trace(data=trw)\n",
    "    trw.stats.sampling_rate = t.stats.sampling_rate\n",
    "    trw.stats.npts          = len(trw)\n",
    "    trw.stats.station       = t.stats.station\n",
    "    trw.stats.starttime     = t.stats.starttime\n",
    "    trw.stats.network       = t.stats.network   \n",
    "    trw.stats.channel       = \"HHZ\"                     # Assign channel code\n",
    "    trw.stats.location      = \"0\"                       # Assign location code\n",
    "    trw.stats.distance      = float(t.stats.distance) - float(gather[0].stats.distance)\n",
    "#\n",
    "    st += trw\n",
    "#\n",
    "#------ Control\n",
    "print(f\"\\n>> Created an array nwGather with processed traces, with shape {np.shape(nwGather)}. Each column is a processed trace.\")\n",
    "#\n",
    "print(f\"\\n>> Created a new processed gather with {len(st)} traces, with {int(st[0].stats.npts)} data points.\")\n",
    "print(f\"    From {st[0].stats.distance} to {st[-1].stats.distance}m. The sampling rate is {st[0].stats.sampling_rate}Hz.\")\n",
    "print(f\"    The new time window is {st[0].stats.endtime - st[-1].stats.starttime}s.\")\n",
    "print(f\"\\n>> Plot of phone {phone+1}:\")\n",
    "#--- Whitened trace has more points than the original one! Adjust time here.\n",
    "dummy = st[phone].times(type=\"relative\")\n",
    "dummy = np.linspace(dummy[0], dummy[-1], num = len(st[phone]))\n",
    "#--- Freq. axis (HZ). f=0 is not discarded here\n",
    "fNy = st[phone].stats.sampling_rate / 2.         # Nyquist\n",
    "freq = np.linspace(0, fNy, np.shape(nwGather)[0])\n",
    "#--- Plot\n",
    "p.pltTrSp( st[phone].times(type=\"relative\"), st[phone], freq, abs(nwGather[:,phone]),\n",
    "              x1label='s', y1label='Ampl.', y1log=False, clr1 = 'k', \n",
    "              x2label='Hz', y2label='Spec.', y2log=True, clr2 = 'r' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambient Noise Cross-correlation\n",
    "- Given two seismometers, $u_1$ and $u_2$, on the surface, will record ground motion as a function of time. Over long periods of time, the cross-correlation of ground motions is\n",
    "$$C_{1,2}\\left(\\tau\\right)=\\int u_{1}\\left(t\\right)\\,u_{2}\\left(t+\\tau\\right)dt$$\n",
    "\n",
    "- Phone 1 will be considered as a source for all other phones as Crios-I is due N from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================== Cross correlation on phone pairs ======================\n",
    "\"\"\"\n",
    "print(f'\\n>> Phone spatial sampling is {loc84S[1, 1] - loc84S[0, 1]}m,')\n",
    "print(f'    while the gather is {loc84S[-1, 1] - loc84S[0, 1]}m long.')\n",
    "#\n",
    "#------ Change distances making phone 1 to be at 0m, instead of 200m; the source for all other phones.\n",
    "#       Remove the useless 3rd column\n",
    "loc84S[:,1] = loc84S[:,1] - loc84S[0,1]\n",
    "loc84S = loc84S[:, :2]\n",
    "#\n",
    "#------ Phone 1 is the source for all other phones in a shot gather. Therefore it is necessary to\n",
    "#        take the conjugate, to multiply it by the corresponding of the receivers'.\n",
    "nwGather[:, 0] = np.conjugate(nwGather[:, 0])\n",
    "#\n",
    "#------ Datetime object list to be used in correlation\n",
    "dataS_t = [st[0].stats.starttime]\n",
    "#\n",
    "#------ Enter max lag\n",
    "ent = st[0].stats.endtime - st[0].stats.starttime\n",
    "ent = input(f'\\n<< Enter max lag time <={round(ent,1)} (rtn = {int(ent)}s):') or str(int(ent))\n",
    "ent = ent.rstrip().split(' ')\n",
    "maxlag = float(ent[0])\n",
    "#\n",
    "#------ Loop trhough the phone pairs from phone 1 to 12. Keep phone 1 as the source -> 11 xcorr.\n",
    "#--- Initialize. The O/P from correlate has 1 fewer point than the I/P traces.\n",
    "xcorr  = np.zeros((nwGather.shape[0] - 1, nwGather.shape[1] - 1))\n",
    "tstamp = xcorr.copy(); nxcorr = xcorr.copy()\n",
    "#--- The source\n",
    "tr0W = nwGather[:,0]\n",
    "#--- Iterate from 0 to the number of columns-1. NB: t_corr is a timestamp object\n",
    "for i in range(1, nwGather.shape[1]):                         #nwGather.shape[1] - 1\n",
    "    tr1W = nwGather[:, i]\n",
    "#    corr| Tstamp| #segments          source|receiver|time sampling     |Datetime list\n",
    "    tdata, t_corr, n_corr = u.correlate(tr0W, tr1W,   st[0].stats.delta, dataS_t,\n",
    "                                        MTparam[3], MTparam[4], maxlag, method = 'xcorr')\n",
    "    xcorr[:,  i - 1] = tdata\n",
    "    tstamp[:, i - 1] = t_corr\n",
    "    nxcorr[:, i - 1] = n_corr\n",
    "#\n",
    "#------- A sequential time for the x-correlation\n",
    "tvec = np.linspace(-maxlag, maxlag, xcorr.shape[0])    #maxlag+dt\n",
    "#\n",
    "#------- Plot correlation between phone 1 and another\n",
    "print(f'\\n>> Plot correlation between phones 1 and {phone+1}, with a distance of {loc84S[phone, 1]}m')\n",
    "#\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "ax.plot(tvec,xcorr[:, phone-1])\n",
    "ax.set_xlabel(\"Time [s]\")\n",
    "ax.set_ylabel(\"Amplitude\")\n",
    "#ax.set_title('Cross-Correlation Function Between %s and %s'%(ssta,rsta))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to retrieve last value\n",
    "ent = input(f'\\n<< copy(rtn=y))?') or 'y'\n",
    "if ent == 'y': \n",
    "    xcorr  = Sxcorr.copy()\n",
    "    tvec   = Stvec.copy()\n",
    "    nxcorr = Snxcorr.copy()\n",
    "else:\n",
    "    Sxcorr  = xcorr.copy()\n",
    "    Stvec   = tvec.copy()\n",
    "    Snxcorr = nxcorr.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================== Construct a cross correlation signal ======================\n",
    "\"\"\"\n",
    "#\n",
    "#------- Choose cross correlation part\n",
    "ent = input(f'\\n<< Acausal (a) or causal (c) of {maxlag}s x-corr(rtn=c))?') or 'c'\n",
    "ent = ent.rstrip().split(' ')[0]\n",
    "if ent not in ['a', 'c']: raise ValueError(f\"'{ent}' not allowed\")\n",
    "if ent == 'a': raise ValueError(f\"'{ent}' not implemented yet\")\n",
    "#\n",
    "#------- Go through all traces, slicing apropriately. \n",
    "i = np.where(tvec >= 0)[0] if ent == 'c' else np.where(tvec < 0)[0]\n",
    "xcorr  = xcorr[i,:]\n",
    "tvec   = tvec[i]\n",
    "nxcorr = nxcorr[i,:]\n",
    "#\n",
    "print(f'>> Work with the {ent[0]}-part with len={len(xcorr)}')\n",
    "#\n",
    "#------ Produce a new gather. Initialization\n",
    "xst = Stream()\n",
    "#--- Loop through traces\n",
    "for i in range(0, xcorr.shape[1]):\n",
    "    t                     = Trace(data=xcorr[:, i])\n",
    "    t.stats.sampling_rate = np.absolute(tvec[1] - tvec[0])    #caters for both a and c parts\n",
    "    t.stats.npts          = len(tvec)\n",
    "    t.stats.station       = str(i)\n",
    "    t.stats.starttime     = st[0].stats.starttime\n",
    "    t.stats.network       = st[0].stats.network \n",
    "    t.stats.channel       = \"HHZ\"                     # Assign channel code\n",
    "    t.stats.location      = \"0\"                       # Assign location code\n",
    "    t.stats.distance      = st[i+1].stats.distance\n",
    "#--- Taper ends with 0.05\n",
    "    t.taper(type = 'hann', max_percentage = 0.025)\n",
    "#--- Add trace to stream\n",
    "    xst += t\n",
    "#\n",
    "#------ Plot Seismogram\n",
    "xst.plot(type='section',\n",
    "        scale=1.3, alpha=.7,\n",
    "        orientation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================== Work with cross correlation signal ======================\n",
    "\"\"\"\n",
    "#\n",
    "#------ Dispersion for frequency axis: 101 values\n",
    "#                   |   fmim  |    fmax   |nfreq|\n",
    "fdisp = np.linspace(MTparam[3], MTparam[4], 401)\n",
    "#\n",
    "#------ Augment traces\n",
    "# Nfft = int(next_fast_len(int(xcorr.shape[0])))\n",
    "Nfft = int(xcorr.shape[0])\n",
    "#\n",
    "#------ \n",
    "#                      |---------- Nyquist ----------|\n",
    "freq = np.linspace(0., xst[0].stats.sampling_rate / 2.)\n",
    "Fxcoor = np.zeros((Nfft//2+1, xcorr.shape[1]),dtype=xcorr.dtype)\n",
    "vf     = np.zeros((Nfft//2+1, xcorr.shape[1]),dtype=xcorr.dtype)\n",
    "#\n",
    "#------ Velocity dispersion -> lvdispsp  100.0 1000.0 401\n",
    "#                    |vmim| vmax| nvel|\n",
    "vdispsp = np.linspace(100., 1000., 401)\n",
    "\n",
    "for i in range(0, xcorr.shape[1]):\n",
    "    Fxcoor[:, i] = np.fft.rfft(xcorr[:, i])\n",
    "#    Fxcoor[:, i] = scipy.fftpack.fft(xcorr[:, i], Nfft)\n",
    "#--- Interpolate velocities\n",
    "    vf[:, i]     = np.interp(Fxcoor[:, i], fdisp, vdispsp)\n",
    "#\n",
    "#------ nt, nr = 11 200\n",
    "#      xcorr.T size `nx x nt`\n",
    "nt, nr = xcorr.shape\n",
    "dt = tvec[1] - tvec[0]\n",
    "#--- len(t) = 200 -> tvec[;,i]; f= 0.0 14.072142857142751 100\n",
    "f = sp.fftpack.fftfreq(nt, dt)[:nt//2+1]\n",
    "\n",
    "#df = f[1] - f[0]\n",
    "#fmax_idx = int(MTparam[4]//df)      #fmax_idx 281\n",
    "fmax_idx = len(f)\n",
    "\n",
    "\n",
    "#\n",
    "#------ Phase velocity range -> C  100.0 997.75 400\n",
    "\n",
    "c = np.arange(vdispsp[0], vdispsp[-1], vdispsp[1]-vdispsp[0])\n",
    "\n",
    "#\n",
    "#------ x 0.0 60.0 11\n",
    "dx = xst[0].stats.distance\n",
    "x = np.linspace(0.0, (nr-1)*dx, nr)\n",
    "#\n",
    "#------ Fx spectrum -> U (11, 100)\n",
    "U = sp.fftpack.fft(xcorr.T)[:, :nt//2]\n",
    "\n",
    "#\n",
    "#------ Dispersion panel\n",
    "disp = np.zeros((len(c), fmax_idx))\n",
    "\n",
    "for fi in range(fmax_idx-1):    #range(fmax_idx)\n",
    "    for ci in range(len(c)):\n",
    "        k = 2.0*np.pi*f[fi]/(c[ci])\n",
    "        disp[ci, fi] = np.abs(\n",
    "                np.dot(dx * np.exp(1.0j*k*x), U[:, fi]/np.abs(U[:, fi])))\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4), gridspec_kw={'width_ratios': [1, 2]})\n",
    "axs[0].imshow(xcorr, cmap='gray', vmin=-.1, vmax=.1, extent=[x[0], x[-1], tvec[-1], tvec[0]])\n",
    "axs[0].axis('tight')\n",
    "axs[0].set_xlabel('Offset [m]')\n",
    "axs[0].set_ylabel('Time [s]')\n",
    "axs[0].set_title('Shot gather')\n",
    "axs[1].imshow(disp, origin='lower', extent=(f[0], f[-1], vdispsp[0], vdispsp[-1]))\n",
    "axs[1].plot(f, vf, 'w', lw=4)  #vf*1e3\n",
    "axs[1].axis('tight')\n",
    "axs[1].set_xlim(0, 45)\n",
    "axs[1].set_ylabel('Velocity [m/s]')\n",
    "axs[1].set_xlabel('Frequency [Hz]')\n",
    "axs[1].set_title('Dispersion panel');\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylops\n",
    "import warnings\n",
    "from pylops.signalprocessing import FFT2D\n",
    "from functools import partial\n",
    "from scipy.optimize import minimize, Bounds\n",
    "from disba import PhaseDispersion\n",
    "import scipy as sp\n",
    "\n",
    "\"\"\"\n",
    "inversion.py\n",
    "\"\"\"\n",
    "def fun(x, nlayers, t, vdispobs, dc=0.005):\n",
    "    r\"\"\"Surface wave inversion misfit function\n",
    "\n",
    "    Create a dispersion curve from the input parameters \n",
    "    (thicknesses and shear wave velocities) and compute\n",
    "    misfit\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : :obj:`numpy.ndarray`\n",
    "        Set of thicknesses and shear wave velocities\n",
    "    t : :obj:`numpy.ndarray`\n",
    "        Period\n",
    "    vdispobs : :obj:`numpy.ndarray`\n",
    "        Observed dispersion curve\n",
    "    dc : :obj:`float`\n",
    "        Phase velocity increment for root finding.\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    loss : :obj:`float`\n",
    "        Loss function\n",
    "\n",
    "    \"\"\"\n",
    "    # Create model\n",
    "    thick = x[:nlayers]\n",
    "    vs = x[nlayers:]\n",
    "    vp = vs * 4\n",
    "    rho = 1. * np.ones(nlayers)\n",
    "    model = np.vstack([thick, vp, vs, rho]).T\n",
    "    \n",
    "    # Compute the Rayleigh-wave modal dispersion curves\n",
    "    pd = PhaseDispersion(*model.T, dc=dc)\n",
    "    cpr = pd(t, mode=0, wave=\"rayleigh\") \n",
    "    vdisp = cpr[1]\n",
    "\n",
    "    return np.linalg.norm(vdisp-vdispobs)\n",
    "\n",
    "\"\"\"\n",
    "dispersionspectra.py\n",
    "\"\"\"\n",
    "def parkdispersion(data, dx, dt, cmin, cmax, dc, fmax):\n",
    "    \"\"\"Dispersion panel\n",
    "    \n",
    "    Calculate dispersion curves using the method of\n",
    "    Park et al. 1998\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : :obj:`numpy.ndarray`\n",
    "        Data of size `nx x nt`\n",
    "    dx : :obj:`float`\n",
    "        Spatial sampling\n",
    "    dt : :obj:`float`\n",
    "        Time sampling\n",
    "    cmin : :obj:`float`\n",
    "        Minimum velocity\n",
    "    cmax : :obj:`float`\n",
    "        Maximum velocity\n",
    "    dc : :obj:`float`\n",
    "        Velocity sampling\n",
    "    fmax : :obj:`float`\n",
    "        Maximum frequency\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    f : :obj:`numpy.ndarray`\n",
    "        Frequency axis\n",
    "    c : :obj:`numpy.ndarray`\n",
    "        Velocity axis`\n",
    "    disp : :obj:`numpy.ndarray`\n",
    "        Dispersion panel of size `nc x nf`\n",
    "    \"\"\"\n",
    "    nr, nt = data.shape\n",
    "    \n",
    "    # Axes\n",
    "    t = np.linspace(0.0, nt*dt, nt)\n",
    "\n",
    "    f = sp.fftpack.fftfreq(nt, dt)[:nt//2]\n",
    "    df = f[1] - f[0]\n",
    "    fmax_idx = int(fmax//df)\n",
    "\n",
    "    c = np.arange(cmin, cmax, dc)  # set phase velocity range\n",
    "    x = np.linspace(0.0, (nr-1)*dx, nr)\n",
    "\n",
    "    # Fx spectrum\n",
    "    U = sp.fftpack.fft(data)[:, :nt//2]\n",
    "    \n",
    "    # Dispersion panel\n",
    "    disp = np.zeros((len(c), fmax_idx))\n",
    "    for fi in range(fmax_idx):\n",
    "        for ci in range(len(c)):\n",
    "            k = 2.0*np.pi*f[fi]/(c[ci])\n",
    "            disp[ci, fi] = np.abs(\n",
    "                np.dot(dx * np.exp(1.0j*k*x), U[:, fi]/np.abs(U[:, fi])))\n",
    "\n",
    "    return f[:fmax_idx], c, disp\n",
    "\"\"\"\n",
    "surfacewaves.py\n",
    "\"\"\"\n",
    "def _tcrop(t):\n",
    "    \"\"\"Crop time axis with even number of samples\"\"\"\n",
    "    if len(t) % 2 == 0:\n",
    "        t = t[:-1]\n",
    "        warnings.warn(\"one sample removed from time axis...\")\n",
    "    return t\n",
    "\n",
    "\n",
    "def ormsby(t, f=(5.0, 10.0, 45.0, 50.0), taper=None):\n",
    "    r\"\"\"Ormsby wavelet\n",
    "\n",
    "    Create a Ormsby wavelet given time axis ``t`` and frequency range\n",
    "    defined by four frequencies which parametrize a trapezoidal shape in\n",
    "    the frequency spectrum.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t : :obj:`numpy.ndarray`\n",
    "        Time axis (positive part including zero sample)\n",
    "    f : :obj:`tuple`, optional\n",
    "        Frequency range\n",
    "    taper : :obj:`func`, optional\n",
    "        Taper to apply to wavelet (must be a function that\n",
    "        takes the size of the window as input\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    w : :obj:`numpy.ndarray`\n",
    "        Wavelet\n",
    "    t : :obj:`numpy.ndarray`\n",
    "        Symmetric time axis\n",
    "    wcenter : :obj:`int`\n",
    "        Index of center of wavelet\n",
    "\n",
    "    \"\"\"\n",
    "    def numerator(f, t):\n",
    "        \"\"\"The numerator of the Ormsby wavelet\"\"\"\n",
    "        return (np.sinc(f * t) ** 2) * ((np.pi * f) ** 2)\n",
    "\n",
    "    t = _tcrop(t)\n",
    "    t = np.concatenate((np.flipud(-t[1:]), t), axis=0)\n",
    "    f1, f2, f3, f4 = f\n",
    "\n",
    "    pf43 = (np.pi * f4) - (np.pi * f3)\n",
    "    pf21 = (np.pi * f2) - (np.pi * f1)\n",
    "    w = (\n",
    "        (numerator(f4, t) / pf43)\n",
    "        - (numerator(f3, t) / pf43)\n",
    "        - (numerator(f2, t) / pf21)\n",
    "        + (numerator(f1, t) / pf21)\n",
    "    )\n",
    "    w = w / np.amax(w)\n",
    "    wcenter = np.argmax(np.abs(w))\n",
    "\n",
    "    # apply taper\n",
    "    if taper is not None:\n",
    "        w *= taper(len(t))\n",
    "\n",
    "    return w, t, wcenter\n",
    "\n",
    "def surfacewavedata(nt, dt, nx, dx, nfft, fdisp, vdisp, wav):\n",
    "    r\"\"\"Surface wave data\n",
    "    Synthetise surface wave only seismic data from dispersion relation\n",
    "    Parameters\n",
    "    ----------\n",
    "    nt : :obj:`int`         number of time samples\n",
    "    dt : :obj:`float`         time sampling \n",
    "    nx : :obj:`int`         number of spatial samples\n",
    "    dx : :obj:`float`         spatial sampling\n",
    "    nx : :obj:`int`        number of fft samples\n",
    "    fdisp : :obj:`int`         frequency axis of dispersion relation\n",
    "    vdisp : :obj:`int`         velocity axis of dispersion relation in km/s\n",
    "    wav : :obj:`numpy.ndarray`         source wavelet\n",
    "    Returns\n",
    "    -------\n",
    "    dshift : :obj:`numpy.ndarray`\n",
    "    \"\"\"\n",
    "    # Axes and gridded phase velocity\n",
    "    t, x = np.arange(nt)*dt, np.arange(nx)*dx\n",
    "    f = np.fft.rfftfreq(nfft, dt)\n",
    "    vf = np.interp(f, fdisp, vdisp)\n",
    "\n",
    "    # Create data\n",
    "    data = np.outer(wav, np.ones(nx)).T\n",
    "    D = np.fft.rfft(data, n=nfft, axis=1)\n",
    "\n",
    "    # Define and apply freq-dependant shifts\n",
    "    shifts = np.outer(x, 1e-3/vf)\n",
    "    shifts = np.exp(-1j * 2 * np.pi * f[np.newaxis, :] * shifts)\n",
    "\n",
    "    Dshift = D * shifts\n",
    "    dshift = np.fft.irfft(Dshift, n=nfft, axis=1)[:, :nt]\n",
    "\n",
    "    return dshift, f, vf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dispersion of Surface waves\n",
    "Velicity dispersion panels can be seen as a FK transform stretched over the K axis. There are different approaches to compute dispersion panels; here we usie the Park method.\n",
    "\n",
    "1) Consider a a parametrized layered medium, where each layer is defined by the following 4 parameters: $\\left(\\Delta z,v_{p},\\rho\\right)$.\n",
    "2) In a layered medium, the elastic wave equation can be turned ino an eigenvalue problem whose solution is the surface wave dispersion curve. This is referred in the literature as Dunkin's matrix algorithm.\n",
    "3) Parameters\n",
    "| Material | Thickness(km) | $V_P$(km/s) | $V_S$(km/s) | Density(g/cm3) |\n",
    "| :-: | -: | -: | -: | -: |\n",
    "| Firn | 0.1 | 2.5-3 | 1.2‚Äì2 | 0.7 |\n",
    "| Ice | 2 | 3.8 | 2 | 0.9 |\n",
    "| Granite | $\\infty$ | 4500 | 3500 | 2.8 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================== A dispersion curve for the above model ======================\n",
    "\"\"\"\n",
    "# \n",
    "#------ Define thickness(km), Vp(km/s), Vs(km/s), density(g/cm3)\n",
    "thick = np.array([0.1, 2, 10])\n",
    "vs = np.array([1.5, 2, 3.5])\n",
    "true_model = np.vstack([thick, vs*4, vs, np.ones(3)]).T\n",
    "\n",
    "# Frequency axis\n",
    "fdisp = np.linspace(2, 50, 101)\n",
    "\n",
    "# Periods (must be sorted starting with low periods)\n",
    "period = np.flipud(1/fdisp)\n",
    "\n",
    "# Rayleigh-wave fundamental model dispersion curve \n",
    "pd = PhaseDispersion(*true_model.T)\n",
    "cpr = pd(period, mode=0, wave=\"rayleigh\") \n",
    "vdisp = np.flipud(cpr[1]) # flip it back to show it as function of f instead of period\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(fdisp, vdisp, 'k', lw=4)\n",
    "plt.xlabel('f [hz]')\n",
    "plt.ylabel('v [km/s]')\n",
    "plt.title('Rayleigh-wave dispersion curve');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic seismogram of surface-wave only shot gather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------  Axes\n",
    "nt = 600 # number of time samples\n",
    "dt = 0.008 # time sampling in s\n",
    "nx = 201 # number of spatial samples\n",
    "dx = 2 # spatial sampling in m\n",
    "nfft = 2**10\n",
    "t, x = np.arange(nt)*dt, np.arange(nx)*dx\n",
    "# Wavelet\n",
    "wav = ormsby(t[:nt//2+1], f=[2, 4, 38, 40], taper=np.hanning)[0][:-1]\n",
    "wav = np.roll(np.fft.ifftshift(wav), 20) # apply small shift to make it causal\n",
    "\n",
    "dshift, f, vf = surfacewavedata(nt, dt, nx, dx, nfft, fdisp, vdisp, wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from f-kx to f-velocity\n",
    "nvel = 401\n",
    "vlims = (1000, 2000)\n",
    "vdispsp = np.linspace(vlims[0], vlims[1], nvel)\n",
    "Ddispsp = parkdispersion(dshift, dx, dt, vlims[0], vlims[1], vdispsp[1]-vdispsp[0], f[-1])[2]\n",
    "#\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4), gridspec_kw={'width_ratios': [1, 2]})\n",
    "axs[0].imshow(dshift.T, cmap='gray', vmin=-.1, vmax=1, extent=[x[0], x[-1], t[-1], t[0]])\n",
    "axs[0].axis('tight')\n",
    "axs[0].set_xlabel('Offset [m]')\n",
    "axs[0].set_ylabel('Time [s]')\n",
    "axs[0].set_title('Shot gather')\n",
    "axs[1].imshow(Ddispsp, origin='lower', extent=(f[0], f[-1], vdispsp[0], vdispsp[-1]))\n",
    "axs[1].plot(f, vf*1e3, 'w', lw=4)\n",
    "axs[1].axis('tight')\n",
    "axs[1].set_xlim(0, 45)\n",
    "axs[1].set_ylabel('Velocity [m/s]')\n",
    "axs[1].set_xlabel('Frequency [Hz]')\n",
    "axs[1].set_title('Dispersion panel');"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
