{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeMSvOAPfX5S"
   },
   "source": [
    "---\n",
    "# Unit08: The Network and Array Methods\n",
    "\n",
    "This notebook has the activities of the Course **ProSeisSN**. It deals with time series processing using a passive seismic dataset using [ObsPy](https://docs.obspy.org/).\n",
    "\n",
    "#### Dependencies: Obspy, Numpy, Matplotlib\n",
    "#### Reset the Jupyter/IPython notebook in order to run it again, press:\n",
    "***Kernel*** -> ***Restart & Clear Output***\n",
    "#### The code $\\Downarrow$ BELOW $\\Downarrow$ runs a notebook with other dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "uzMJ-lGlkGuK",
    "outputId": "66c27f9e-fd21-4a54-ed6d-6a23b77ec540",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#------ Import Libraries\n",
    "import sys\n",
    "import os\n",
    "    \n",
    "#------ Work with the directory structure to include auxiliary codes\n",
    "print('\\n Local directory ==> ', os.getcwd())\n",
    "print('  - Contents: ', os.listdir(), '\\n')\n",
    "\n",
    "path = os.path.abspath(os.path.join('..'))\n",
    "if path not in sys.path:\n",
    "    sys.path.append(path+\"/CodePy\")\n",
    "\n",
    "%run ../CodePy/ImpMod.ipynb\n",
    "\n",
    "#------ Alter default matplotlib rcParams\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.dates as dates\n",
    "# Change the defaults of the runtime configuration settings in the global variable matplotlib.rcParams\n",
    "plt.rcParams['figure.figsize'] = 9, 5\n",
    "#plt.rcParams['lines.linewidth'] = 0.5\n",
    "plt.rcParams[\"figure.subplot.hspace\"] = (.9)\n",
    "\n",
    "#------ Magic commands\n",
    "%matplotlib inline\n",
    "%matplotlib widget\n",
    "#%pylab notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Read **file 3804** data from TTB22\n",
    "- **The Receiver Array**\n",
    "The array has 24 GS-20DX vertical geophones hooked to a $L=69$m cable, using takeouts spaced $\\delta l=6$m from each other. The GS-20DX geophones have a natural frequency of $f_n=10\\textrm{Hz}$, and a spurious frequency $f_{sp}>250$Hz. The array has a irregular circular shape, deployed in the Southern tip of the island, with its center at $\\left(1^{\\circ}12^{\\prime}6.93^{\\prime\\prime}\\textrm{S},48^{\\circ}30^{\\prime}23.39^{\\prime\\prime}\\textrm{S}\\right)$.\n",
    "- **The data**\n",
    "Each of the 12 traces of **file 3804** is $\\Delta T=60$s long, with a sampling frequency of $f_{s}=250$Hz. This file was recorded on 2022-04-02, begining at 13h 56min 41s. That was during the maximum gradient of the local ebb tide.\n",
    "\n",
    "<img src=\"./ttb_tide.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================== READ THE SEISMIC DATA LOCALLY ======================\n",
    "\"\"\"\n",
    "#\n",
    "#------ Read the seismic data\n",
    "filename = '3804'\n",
    "print(f\">> Read with data file {filename}\")\n",
    "filename = '../Data/'+filename+'.dat'   \n",
    "#------- Read the data file as a SEG2 object\n",
    "st = read(filename)\n",
    "#\n",
    "#------- Print stream information\n",
    "dummy = float(st[-1].stats.seg2.RECEIVER_LOCATION)\n",
    "print(f\"1) Gather acquired on {st[0].stats.starttime}, has {len(st)} geophones along {dummy}m.\")\n",
    "dummy = (UTCDateTime(st[0].stats.endtime) - UTCDateTime(st[0].stats.starttime))\n",
    "print(f\"2) Each {dummy}s-long trace has {int(st[0].stats.npts)} data points.\")\n",
    "print(f\"3) The sampling frequency is {st[0].stats.sampling_rate}Hz\")\n",
    "#\n",
    "\"\"\"\n",
    "====================== READ PHONES LOCATIONS ======================\n",
    "\"\"\"\n",
    "#------ Read the phones cartesian locations\n",
    "#--- Reads the CSV file with (x, y)m locations\n",
    "ttb_loc = u.RGloc('../Data/'+'ttb_loc.dat')\n",
    "#------ Read the phones geographic locations\n",
    "#--- Reads the CSV file with (lat,lon) in degress locations\n",
    "ttb_gloc = u.RGloc('../Data/'+'ttb_gloc.dat')\n",
    "#\n",
    "#------ Plot gather in cartesian\n",
    "p.pgather(ttb_loc[:,1], ttb_loc[:,2], ttb_loc[:,0], coord='cartesian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Display all the data as a seismogram\n",
    "- Use the experience with one trace to process the whole stream together.\n",
    "- A distance dependent plot shows the different move-out of seismic arrivals and gives an idea of the  backazimuth and slowness that could be expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#------ Create a new stream from the SEG2 stream. Gather baricenter = bcenter\n",
    "gather, bcenter = u.creastrm(st, ttb_gloc)\n",
    "#------- Filter the stream\n",
    "#--- Filter parameters\n",
    "MTparam = [1, 1, 'bp',  5., 50., 1, 0]\n",
    "# └─────> [dtr, line, ftype, Fmin, Fmax, taper, gain]\n",
    "gather = u.otrstr(gather, MTparam)\n",
    "#\n",
    "#------ Plot\n",
    "gather.plot(type='section',\n",
    "            scale=1.3, alpha=.7,\n",
    "            orientation='horizontal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\Downarrow$ Zoom in the above seismogram $\\Downarrow$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#------ Zoom in the seismogram\n",
    "ent = input(f' Enter t0 and t1 to zoom: ')\n",
    "ent = ent.rstrip().split(' ')\n",
    "f0 = float(ent[0])\n",
    "f1 = float(ent[1])\n",
    "#\n",
    "dt = gather[0].stats.starttime\n",
    "gather.plot(type='section',\n",
    "            scale=1.3, alpha=.7,\n",
    "            starttime=dt+f0, endtime=dt+f1,\n",
    "            orientation='horizontal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Matched-filter detection\n",
    "- Create a catalog of **template waveforms** from file 3804 to generate characteristic functions that could be used for detection.\n",
    "- Once the catalog is created it is necessary to provide two paramters:\n",
    "1) The correlation threshold within the normalised correlation range [-1, 1]\n",
    "2)  The triger off time in s. This is the minimum distance between events.\n",
    "#### The code $\\Downarrow$ BELOW $\\Downarrow$ resets the event catalog to an empty list: it should be run at least once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ Reset event catalog\n",
    "try:\n",
    "    del cat\n",
    "except:\n",
    "    cat   = [] #-> wavefrom catalog\n",
    "    tname = [] #-> template names\n",
    "print(f\">> Event catalog reset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code $\\Downarrow$ BELOW $\\Downarrow$ can be run many times to build the catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Build a catalog of templates. \n",
    "\"\"\"\n",
    "#------ Construct catalog\n",
    "#------ Pick up a phone\n",
    "dummy = np.random.randint(1, len(st)+1)\n",
    "ent = input(f' Enter a phone [dflt=random] ')\n",
    "ent = int( ent.rstrip().split(' ')[0] ) if ent else dummy\n",
    "#------- The trace = Phone -1.\n",
    "trZ = gather[ent - 1].copy()\n",
    "#\n",
    "#------ Plot Spectrogram\n",
    "time = trZ.times(type=\"relative\")\n",
    "p.Pspect(time, trZ)\n",
    "#\n",
    "#-------- Construct catalog of template waveforms with names\n",
    "cat, tname = u.cat_wfrm(trZ, cat, tname, ent)\n",
    "#\n",
    "print(f\">> Template catalog has {len(cat)} templates: {tname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Detect events with the Matched-filter detection algorithms\n",
    "Work with a single trace. It is necessary to provide two paramters:\n",
    "- The correlation threshold within the normalised correlation range [-1, 1]\n",
    "- The triger off time in s. This is the minimum distance between events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ Import Packages\n",
    "from obspy.signal.cross_correlation import correlation_detector\n",
    "import pprint\n",
    "print(f\">> Trigger packages imported.\")\n",
    "#\n",
    "#------ Enter height and distance (s). Hint: .6 1\n",
    "ent = input(f'<< Enter correlation threshold and triger off time(s): ')\n",
    "ent = ent.rstrip().split(' ')\n",
    "corthr   = float(ent[0])\n",
    "trgoff   = float(ent[1])\n",
    "#\n",
    "stream = Stream()\n",
    "for i in range(0, len(gather), 6):\n",
    "    stream  = Stream([gather[i]])\n",
    "#\n",
    "#------ Detections. Free memory on each loop.\n",
    "    detect = []\n",
    "    for template in cat:\n",
    "        tmplstr = Stream([template])\n",
    "        dets, sims = correlation_detector(\n",
    "                       stream=stream, templates=[tmplstr],\n",
    "                       heights=corthr, distance=trgoff, plot=stream,\n",
    "                       template_names=tname )\n",
    "        detect.extend(dets)\n",
    "#\n",
    "    print(\"Trace {0} has {1} detections from {2} templates\".format(i+1, len(detect), len(cat)))\n",
    "    print(detect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing DOA with sliding-window array processing\n",
    "\n",
    "The next code block applies the least-squares method for estimating the DOA in a sliding-window. You can specify the start and end time to process, the length of the time window, and the overlap. The output is a list of times, phase velocities, and backazimuths. The subsequent plot shows the results with the beamformed waveform for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#------ Get the array coordinates\n",
    "X, stn = u.acoord(gather, bcenter)\n",
    "#\n",
    "#------ Enter the sliding-window parameters\n",
    "print(f'>> Provide the parameters for estimating the DOA with a sliding-window:')\n",
    "print(f'   1) twin         -> length of the time window;')\n",
    "print(f'   2) twstep       -> the window step')\n",
    "print(f'   3) tstart, tend -> the relative start and end times to process;')\n",
    "#\n",
    "ent = input(f'<< Enter twin, twstep, tstart, and tend: ') or '1.2 0.2 30 40'\n",
    "twin, twstep, tstart, tend = np.array(ent.rstrip().split(' '), dtype=float)\n",
    "#\n",
    "#------------ \n",
    "slid_fk = u.sldtw_fk(gather, tstart, tend, MTparam, win_len=twin, win_frac=twstep)\n",
    "#------------ Convert times to seconds after Stream start time:\n",
    "#T = (slid_fk[:,0] - date2num(st[0].stats.starttime.datetime))*86400\n",
    "\n",
    "\n",
    "#T = (slid_fk[:,0] - date2num(gather[0].stats.starttime.datetime))*86400\n",
    "T = slid_fk[:,0] - gather[0].times(\"matplotlib\")[0]\n",
    "\n",
    "\n",
    "#------------ Convert backazimuths to degrees from North:\n",
    "B = slid_fk[:,3] % 360.\n",
    "#------------ Convert slowness to phase velocity:\n",
    "V = 1/slid_fk[:,4]\n",
    "#------------ Semblance:\n",
    "S = slid_fk[:,1]\n",
    "#------------ Plot. Mwax velocity is vmax\n",
    "vmax =  1.5\n",
    "\n",
    "ent = input(f'<< Enter a phone: ')\n",
    "ent = ent.rstrip().split(' ')\n",
    "p.psw(gather, T, B, V, C=S, v_max=vmax, element=ent[0], twin_plot=[tstart,tend])\n",
    "\n",
    "#\n",
    "#------ Get a list of times, phase velocities, and backazimuths\n",
    "#T, V, B = u.sldtw(gather, X, tstart, tend, twin, overlap)\n",
    "#\n",
    "#------ Plot\n",
    "#st = u.add_beam(gather, bcenter, 'bcenter')\n",
    "#p.psw(gather, T, B, V, v_max=1., twin_plot=[tstart,tend])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent = int(ent) - 1\n",
    "flims = [MTparam[3], MTparam[4]]\n",
    "\"\"\"\n",
    "====================== BEAMFORMING ======================\n",
    "\"\"\"\n",
    "stream = Stream()\n",
    "dummy  = Stream([gather[ent]])\n",
    "print(len(dummy))\n",
    "# ---------- Use FK Analysis\n",
    "out, stime, etime = u.BeamFK(dummy, flims, ttb_gloc)\n",
    "#-- Make output human readable\n",
    "t, rel_power, abs_power, baz, slow = out.T\n",
    "#------------- print\n",
    "sys.stdout.write('\\n')\n",
    "print(f'>> t       rel_power abs_power   baz(deg) slow(s/km)')    \n",
    "for i in range(len(t)):\n",
    "    print(f'   {round(t[i],4)}, {round(rel_power[i],4)}, {round(abs_power[i],4)}, {round(baz[i],4)}, {round(slow[i],4)}')    \n",
    "#------------ Plot\n",
    "p.pltbaz(out, stime , etime)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
