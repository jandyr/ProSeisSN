{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeMSvOAPfX5S"
   },
   "source": [
    "---\n",
    "# Unit08: The Network and Array Methods\n",
    "\n",
    "This notebook has the activities of the Course **ProSeisSN**. It deals with time series processing using a passive seismic dataset using [ObsPy](https://docs.obspy.org/).\n",
    "\n",
    "#### Dependencies: Obspy, Numpy, Matplotlib\n",
    "#### Reset the Jupyter/IPython notebook in order to run it again, press:\n",
    "***Kernel*** -> ***Restart & Clear Output***\n",
    "#### The code $\\Downarrow$ BELOW $\\Downarrow$ runs a notebook with other dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "uzMJ-lGlkGuK",
    "outputId": "66c27f9e-fd21-4a54-ed6d-6a23b77ec540",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#------ Import Libraries\n",
    "import sys\n",
    "import os\n",
    "    \n",
    "#------ Work with the directory structure to include auxiliary codes\n",
    "print('\\n Local directory ==> ', os.getcwd())\n",
    "print('  - Contents: ', os.listdir(), '\\n')\n",
    "\n",
    "path = os.path.abspath(os.path.join('..'))\n",
    "if path not in sys.path:\n",
    "    sys.path.append(path+\"/CodePy\")\n",
    "\n",
    "%run ../CodePy/ImpMod.ipynb\n",
    "\n",
    "#------ Alter default matplotlib rcParams\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.dates as dates\n",
    "# Change the defaults of the runtime configuration settings in the global variable matplotlib.rcParams\n",
    "plt.rcParams['figure.figsize'] = 9, 5\n",
    "#plt.rcParams['lines.linewidth'] = 0.5\n",
    "plt.rcParams[\"figure.subplot.hspace\"] = (.9)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "#------ Magic commands\n",
    "%matplotlib inline\n",
    "%matplotlib widget\n",
    "#%pylab notebook\n",
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Use data files from TTB22\n",
    "- **The Receiver Array**\n",
    "The array has 24 GS-20DX vertical geophones hooked to a $L=69$m cable, using takeouts spaced $\\delta l=6$m from each other. The GS-20DX geophones have a natural frequency of $f_n=10\\textrm{Hz}$, and a spurious frequency $f_{sp}>250$Hz. The array has a irregular circular shape, deployed in the Southern tip of the island, with its center at $\\left(1^{\\circ}12^{\\prime}6.93^{\\prime\\prime}\\textrm{S},48^{\\circ}30^{\\prime}23.39^{\\prime\\prime}\\textrm{S}\\right)$. Each of the 24 gather traces are $\\Delta T=60$s long, with a sampling frequency of $f_{s}=250$Hz.\n",
    "- Get geophone locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\"\"\"\n",
    "====================== READ PHONES LOCATIONS ======================\n",
    "\"\"\"\n",
    "#------ Read the phones cartesian locations\n",
    "#--- Reads the CSV file with (x, y)m locations\n",
    "ttb_loc = u.RGloc('../Data/'+'ttb_loc.dat')\n",
    "#------ Read the phones geographic locations\n",
    "#--- Reads the CSV file with (lat,lon) in degress locations\n",
    "ttb_gloc = u.RGloc('../Data/'+'ttb_gloc.dat')\n",
    "#\n",
    "#------ Plot gather in cartesian\n",
    "p.pgather(ttb_loc[:,1], ttb_loc[:,2], ttb_loc[:,0], coord='cartesian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Read data files from TTB22\n",
    "- **The data**\n",
    "Files 3695 to 3810 were collected during 2h ebb tide with an amplitude of 0.91m.\n",
    "| File | Timestamp | Tide (m) |\n",
    "| :-: | :-: | :-: |\n",
    "| 3695 | 2022-04-02T12:00:15 | 2.70 |\n",
    "| 3810 | 2022-04-02T14:03:06 | 1.79 |\n",
    "- Let's consider only files ???0.dat: [3700.dat, ..., 3810.dat]\n",
    "\n",
    "<img src=\"./ttbtide.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================== READ THE SEISMIC DATA LOCALLY ======================\n",
    "\"\"\"\n",
    "#------ Read the seismic data\n",
    "ent = str(np.random.choice(np.arange(3700, 3811, 10)))\n",
    "ent = input(f'   Enter a file number in [3695, 3810], rtn=random:\\n') or ent\n",
    "ent = ent.rstrip().split(' ')\n",
    "print(f\">> Read with data file {ent}\")\n",
    "ent = '../Data/ttb/'+ent[0]+'.dat'\n",
    "#\n",
    "#------- Read the data file as a SEG2 object\n",
    "\n",
    "print(ent)\n",
    "st = read(ent)\n",
    "#\n",
    "#------- Print stream information\n",
    "dummy = float(st[-1].stats.seg2.RECEIVER_LOCATION)\n",
    "print(f\">> Gather acquired on {st[0].stats.starttime}, has {int(st[0].stats.npts)} data points.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Display all the data as a seismogram\n",
    "- Use the experience with one trace to process the whole stream together.\n",
    "- A distance dependent plot shows the different move-out of seismic arrivals and gives an idea of the  backazimuth and slowness that could be expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#------ Create a new stream from the SEG2 stream. Gather baricenter = bcenter\n",
    "gather, bcenter = u.creastrm(st, ttb_gloc)\n",
    "#------- Filter the stream\n",
    "#--- Filter parameters: change as you choose.\n",
    "MTparam = [1, 1, 'bp',  5., 50., 1, 0]\n",
    "# └─────> [dtr, line, ftype, Fmin, Fmax, taper, gain]\n",
    "gather = u.otrstr(gather, MTparam)\n",
    "#\n",
    "#------ Plot\n",
    "gather.plot(type='section',\n",
    "            scale=1.3, alpha=.7,\n",
    "            orientation='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#------ Zoom in the seismogram\n",
    "ent = input(f' Enter t0 and t1 to zoom: ')\n",
    "ent = ent.rstrip().split(' ')\n",
    "f0 = float(ent[0])\n",
    "f1 = float(ent[1])\n",
    "#\n",
    "dt = gather[0].stats.starttime\n",
    "gather.plot(type='section',\n",
    "            scale=1.3, alpha=.7,\n",
    "            starttime=dt+f0, endtime=dt+f1,\n",
    "            orientation='horizontal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Check frequency contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ Pick up a phone\n",
    "dummy = np.random.randint(1, len(st)+1)\n",
    "ent = input(f' Enter a phone [dflt=random] ')\n",
    "ent = int( ent.rstrip().split(' ')[0] ) if ent else dummy\n",
    "#------- The trace\n",
    "trZ = gather[ent - 1].copy()\n",
    "#       +───────+─> Trace = Phone -1 \n",
    "#------ Relative time: nummpy array\n",
    "time = trZ.times(type=\"relative\")\n",
    "#------ Plot Trace+Spectrogram\n",
    "p.Pspect(time, trZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Array response\n",
    "- A good text for this section: Chap_9.pdf.\n",
    "\n",
    "- We are going to use the ObsPy's FK array analysis modules.\n",
    "\n",
    "- If $\\lambda$ is the wavelength so $\\Rightarrow k=\\frac{1}{\\lambda}$ is the wavenumber. As it goes with frequency, $f=\\frac{1}{T}\\textrm{ and }\\omega=\\frac{2\\pi}{T}$, so does the wavenumber: $\\kappa=\\frac{2\\pi}{\\lambda}$.\n",
    "\n",
    "- If $v_a$ is the apparent velocity along a given direction and $s$ the slowness, the apparent wavenumber is\n",
    "$$fs=\\frac{f}{v_{a}}=\\frac{1}{\\lambda_{a}}=k_{a}=\\frac{\\kappa_{a}}{2\\pi}$$\n",
    "\n",
    "- The array transfer function describes sensitivity and resolution of an array for seismic signals with different frequency range and slownesses $s=\\frac{1}{v_a}$.  The array response is the *Fk* spectrum of a monochromatic wave with amplitude $\\mathcal{A}=e^{\\imath\\boldsymbol{k}_{0}\\cdot\\mathbf{r}}=1$.\n",
    "\n",
    "- The normalized array response for the Bartlett beamformer is\n",
    "$$\\mathcal{A}\\left(f_{0},\\boldsymbol{k},\\boldsymbol{k}_{0}\\right)=\\frac{1}{N}\\sum_{i=1}^{N}e^{\\imath\\left(\\boldsymbol{k}-\\boldsymbol{k}_{0}\\right)\\cdot\\mathbf{r}_{i}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.signal.array_analysis import array_transff_freqslowness, get_geometry\n",
    "#from obspy.signal.array_analysis import clibsignal, cosine_taper, get_geometry, get_timeshift\n",
    "#\n",
    "#------ Frequency range and step\n",
    "ent = input(f' Enter frequency step from {MTparam[3]} to {MTparam[4]} [dflt={MTparam[3]}] ') or str(MTparam[3])\n",
    "ent = float( ent.rstrip().split(' ')[0] )\n",
    "fstp = float(ent)\n",
    "#\n",
    "#------ Slowness maximum and step (s/km)\n",
    "ent = '2.5 0.25' \n",
    "ent = input(f'\\n Enter -> s_max, s_step(rtn={ent}):') or ent\n",
    "ent = ent.rstrip().split(' ')\n",
    "s_max, s_step = [float(dummy) for dummy in ent]\n",
    "#\n",
    "#------ Array geometry\n",
    "coords = np.zeros((len(gather), 3))\n",
    "for i, tr in enumerate(gather):\n",
    "    coords[i,0] = tr.stats.coordinates.latitude\n",
    "    coords[i,1] = tr.stats.coordinates.longitude\n",
    "    coords[i,2] = tr.stats.coordinates.elevation\n",
    "#\n",
    "#------ Compute array response\n",
    "print(f'Estimating array response between [{MTparam[3]:.2f} : {fstp:.2f} : {MTparam[4]:.2f}] Hz')\n",
    "R = array_transff_freqslowness(coords, s_max, s_step, MTparam[3], MTparam[4], fstp, coordsys='lonlat')\n",
    "#-- Build a grid\n",
    "sx = np.arange(-s_max, s_max,+s_step)\n",
    "sy = sx\n",
    "Sx, Sy = np.meshgrid(sx, sy)\n",
    "#\n",
    "#------ Get geometry from ObsPy and plot\n",
    "geo = get_geometry(gather, coordsys='lonlat', return_center=False, verbose=False)\n",
    "#\n",
    "p.par(gather,s_max, R, geo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Beamforming\n",
    "- Window length `win_len` (now set to 20 seconds). You want to set the length such that the frequency of interest fits. So larger windows for lower frequencies. And vice versa.\n",
    "<br/>\n",
    "\n",
    "- Overlap parameter `win_frac` (now to set to 0.5 for 50% overlap). Choose 0.25 for 75%, 0.1 for 90% overlap, etc. Basically the smaller the parameter, the more overlap and the longer the computation time. \n",
    "<br/>\n",
    "\n",
    "- Slowness grid: you can modify the parameters that define the grid. Parameter `sstep` defines the density of the grid. The smaller the steps, the longer the computation time.\n",
    "\n",
    "- In <a href='https://github.com/jdassink/beamforming'>my own code</a> I prefer to define the slowness grid based on the parameters of interest: the back azimuth and the apparent velocity. Therefore I obtain a cylindrical slowness grid. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "# ---------- FK analysis ----------\n",
    "\"\"\" \n",
    "    FK analysis with ObsPy. The data is bandpass filtered, prewhitening disabled.\n",
    "    <Arguments>\n",
    "    stream               -> ditto\n",
    "    frqlow, frqhigh      -> Low corner and high corner of frequency range for array analysis\n",
    "    tstart, tend         -> Relative time limits (s) on the time window for event,\n",
    "                             later to be transformed to UTCDateTime format.\n",
    "    wlen                 -> sliding window for analysis in seconds.\n",
    "    win_frac             -> Overlap fraction (s) fraction. Dflt win_frac = 0.5\n",
    "    baz_plot             -> Whether to show backazimuth-slowness map (True) or\n",
    "                             slowness x-y map (False).\n",
    "\n",
    "\n",
    "    sll_o, sl_s          -> Slowness grid (s/km) and step fraction.\n",
    "                                      slm_y +─────+\n",
    "                                            │  .  │\n",
    "                                            │     │\n",
    "                                      sll_y +─────+    \n",
    "                                         sll_x   slm_x\n",
    "    slx=(min, max)        -> Min/Max slowness for analysis in x direction.\n",
    "    sly=(min, max)        -> Min/Max slowness for analysis in y direction.\n",
    "    sls                   -> step width of slowness grid       \n",
    "\n",
    "\n",
    "    semb_thres, vel_thres -> infinitesimally small numbers; must not be changed.\n",
    "    timestamp             -> Written in 'matlabday', read directly by plotting routine.\n",
    "    static3D              -> Static correction of topography (bool) using `vel_corr` as velocity (slow!)\n",
    "    vel_corr              -> Correction velocity (km/s) for static topography correction\n",
    "\n",
    "    array_response        -> superimpose array reponse function in plot (bool, slow!)\n",
    "\"\"\" \n",
    "#\n",
    "def sldtw_fk(stream, frqlow, frqhigh, wlen, wfrac=None, baz_plot=True,\\\n",
    "             slx=None, sly=None, sls=None,\\\n",
    "             static_3D=False, vel_corr=None, array_response=False, **kwargs):\n",
    "#\n",
    "#------ Auxiliary I/P function\n",
    "    T = lambda T, t: t if T is None else T\n",
    "#\n",
    "#------ Unpack slowness grid\n",
    "# Min/Max slowness --> note default 5km\n",
    "    sllx, slmx = T(slx, (-5., 5.))\n",
    "    slly, slmy = T(sly, (-5., 5.))\n",
    "#\n",
    "#------ Time bookends -> Stream is trimmed -> disabled as all traces have same length\n",
    "    starttime = max([tr.stats.starttime for tr in stream])\n",
    "    endtime   = min([tr.stats.endtime for tr in stream])\n",
    "    stream.trim(starttime, endtime)\n",
    "#--- Dictionary\n",
    "    kwargs = dict(\n",
    "#\n",
    "#------ slowness grid : Xmin , Xmax , Ymin , Ymax , Slow Step --> note default sls=0.025km\n",
    "    sll_x=sllx, slm_x=slmx, sll_y=slly, slm_y=slmy, sl_s=T(sls, 0.025),\n",
    "#\n",
    "#------ sliding window properties\n",
    "#       wlen larger for lower frequencies and vice versa\n",
    "#       wfrac = 0.5 -> 50%, 0.25 for 75%, 0.1 for 90% overlap\n",
    "    win_len=wlen, win_frac=T(wfrac, 0.5),\n",
    "#\n",
    "#------ Frequency properties\n",
    "    frqlow=frqlow, frqhigh=frqhigh, prewhiten=0,\n",
    "#\n",
    "#------ restrict output\n",
    "    verbose=False,   #store=dump, \n",
    "    semb_thres=-1.e9, vel_thres=-1.e9, timestamp='julsec',\n",
    "#\n",
    "#------ Time \n",
    "    stime=starttime, etime=endtime,\n",
    "#\n",
    "        #--- Static correction of topography\n",
    "#    method=0, correct_3dplane=False           #, static_3D=static_3D      vel_cor=vc,\n",
    "#\n",
    "    )\n",
    "#\n",
    "#------ Coordinates\n",
    "    for tr in stream:\n",
    "        tr.stats.coordinates = AttribDict({\n",
    "            'latitude': tr.stats.coordinates['latitude'],\n",
    "            'elevation': tr.stats.coordinates['elevation'],\n",
    "            'longitude': tr.stats.coordinates['longitude']}\n",
    "            )\n",
    "#\n",
    "#------ O/P container\n",
    "#    def dump(pow_map, apow_map, i):\n",
    "#        np.save(filename_patterns[0] % i, pow_map)\n",
    "#        np.save(filename_patterns[1] % i, apow_map)\n",
    "#\n",
    "#    filename = ('../data/pow_map.npy',\\\n",
    "#                '../data/apow_map.npy')\n",
    "#\n",
    "    \"\"\" \n",
    "    try:\n",
    "        # next step would be needed if the correction velocity needs to be\n",
    "        # estimated\n",
    "        #\n",
    "        sllx /= KM_PER_DEG\n",
    "        slmx /= KM_PER_DEG\n",
    "        slly /= KM_PER_DEG\n",
    "        slmy /= KM_PER_DEG\n",
    "        sls /= KM_PER_DEG\n",
    "        vc = vel_corr\n",
    "    \"\"\" \n",
    "#\n",
    "    print(stream)\n",
    "    spl = stream.copy()\n",
    "    vc = vel_corr\n",
    "#\n",
    "#------------ array processing --------------\n",
    "    start = UTCDateTime()\n",
    "    out = array_processing(stream, **kwargs)\n",
    "    print(\"Total time in routine: %f\\n\" % (UTCDateTime() - start))\n",
    "#\n",
    "#------ Make output human readable, adjust backazimuth to values\n",
    "#         between 0 and 360\n",
    "    t, rel_power, abs_power, baz, slow = out.T\n",
    "#\n",
    "    if array_response:\n",
    "        stepsfreq = (frqhigh - frqlow) / 10.\n",
    "        tf_slx = sllx\n",
    "        tf_smx = slmx\n",
    "        tf_sly = slly\n",
    "        tf_smy = slmy\n",
    "        transff = array_transff_freqslowness(\n",
    "            stream, (tf_slx, tf_smx, tf_sly, tf_smy), sls, frqlow,\n",
    "            frqhigh, stepsfreq, coordsys='lonlat',\n",
    "            correct_3dplane=False, static_3D=False, vel_cor=vc)\n",
    "#\n",
    "#------------ plotting --------------\n",
    "#\n",
    "#------ Color map\n",
    "    cmap = cm.rainbow\n",
    "    numslice = len(t)\n",
    "    powmap = []\n",
    "    slx = np.arange(sllx-sls, slmx, sls)\n",
    "    sly = np.arange(slly-sls, slmy, sls)\n",
    "    if baz_plot:\n",
    "        maxslowg = np.sqrt(slmx*slmx + slmy*slmy)\n",
    "        bzs = np.arctan2(sls, np.sqrt(slmx*slmx + slmy*slmy))*180/np.pi\n",
    "        xi = np.arange(0., maxslowg, sls)\n",
    "        yi = np.arange(-180., 180., bzs)\n",
    "        grid_x, grid_y = np.meshgrid(xi, yi)\n",
    "#\n",
    "#------ Reading in the rel-power maps\n",
    "    for i in xrange(numslice):\n",
    "        powmap.append(np.load(filename[0] % i))\n",
    "        if method != 'FK':\n",
    "            trace.append(np.load(filename[1] % i))\n",
    "#\n",
    "#------ \n",
    "    npts = stream[0].stats.npts\n",
    "    df = stream[0].stats.sampling_rate\n",
    "    T = np.arange(0, npts / df, 1 / df)\n",
    "#\n",
    "#------ For windowlen > 0, move through slices\n",
    "    for i in xrange(numslice):\n",
    "        slow_x = np.sin((baz[i]+180.)*np.pi/180.)*slow[i]\n",
    "        slow_y = np.cos((baz[i]+180.)*np.pi/180.)*slow[i]\n",
    "        st = UTCDateTime(t[i]) - starttime\n",
    "        if wlen <= 0:\n",
    "            en = endtime\n",
    "        else:\n",
    "            en = st + wlen\n",
    "        print(UTCDateTime(t[i])) \n",
    "        # add polar and colorbar axes\n",
    "        fig = plt.figure(figsize=(12, 12))\n",
    "        ax1 = fig.add_axes([0.1, 0.87, 0.7, 0.10])\n",
    "        # here we plot the first trace on top of the slowness map\n",
    "        # and indicate the possibiton of the lsiding window as green box\n",
    "        if method == 'FK':\n",
    "            ax1.plot(T, spl[0].data, 'k')\n",
    "            if wlen > 0.:\n",
    "                try:\n",
    "                    ax1.axvspan(st, en, facecolor='g', alpha=0.3)\n",
    "                except IndexError:\n",
    "                    pass\n",
    "        else:\n",
    "            T = np.arange(0, len(trace[i])/df, 1 / df)\n",
    "            ax1.plot(T, trace[i], 'k')\n",
    "\n",
    "        ax1.yaxis.set_major_locator(MaxNLocator(3))\n",
    "\n",
    "        ax = fig.add_axes([0.10, 0.1, 0.70, 0.7])\n",
    "\n",
    "        # if we have chosen the baz_plot option a re-griding\n",
    "        # of the sx,sy slowness map is needed\n",
    "        if baz_plot:\n",
    "            slowgrid = []\n",
    "            transgrid = []\n",
    "            pow = np.asarray(powmap[i])\n",
    "            for ix, sx in enumerate(slx):\n",
    "                for iy, sy in enumerate(sly):\n",
    "                    bbaz = np.arctan2(sx, sy)*180/np.pi+180.\n",
    "                    if bbaz > 180.:\n",
    "                        bbaz = -180. + (bbaz-180.)\n",
    "                    slowgrid.append((np.sqrt(sx*sx+sy*sy), bbaz,\n",
    "                                     pow[ix, iy]))\n",
    "                    if array_response:\n",
    "                        tslow = (np.sqrt((sx+slow_x) *\n",
    "                                 (sx+slow_x)+(sy+slow_y) *\n",
    "                                 (sy+slow_y)))\n",
    "                        tbaz = (np.arctan2(sx+slow_x, sy+slow_y) *\n",
    "                                180 / np.pi + 180.)\n",
    "                        if tbaz > 180.:\n",
    "                            tbaz = -180. + (tbaz-180.)\n",
    "                        transgrid.append((tslow, tbaz,\n",
    "                                          transff[ix, iy]))\n",
    "\n",
    "            slowgrid = np.asarray(slowgrid)\n",
    "            sl = slowgrid[:, 0]\n",
    "            bz = slowgrid[:, 1]\n",
    "            slowg = slowgrid[:, 2]\n",
    "            grid = spi.griddata((sl, bz), slowg, (grid_x, grid_y),\n",
    "                                method='nearest')\n",
    "            ax.pcolormesh(xi, yi, grid, cmap=cmap)\n",
    "\n",
    "            if array_response:\n",
    "                level = np.arange(0.1, 0.5, 0.1)\n",
    "                transgrid = np.asarray(transgrid)\n",
    "                tsl = transgrid[:, 0]\n",
    "                tbz = transgrid[:, 1]\n",
    "                transg = transgrid[:, 2]\n",
    "                trans = spi.griddata((tsl, tbz), transg,\n",
    "                                     (grid_x, grid_y),\n",
    "                                     method='nearest')\n",
    "                ax.contour(xi, yi, trans, level, colors='k',\n",
    "                           linewidth=0.2)\n",
    "\n",
    "            ax.set_xlabel('slowness [s/deg]')\n",
    "            ax.set_ylabel('backazimuth [deg]')\n",
    "            ax.set_xlim(xi[0], xi[-1])\n",
    "            ax.set_ylim(yi[0], yi[-1])\n",
    "        else:\n",
    "            ax.set_xlabel('slowness [s/deg]')\n",
    "            ax.set_ylabel('slowness [s/deg]')\n",
    "            slow_x = np.cos((baz[i]+180.)*np.pi/180.)*slow[i]\n",
    "            slow_y = np.sin((baz[i]+180.)*np.pi/180.)*slow[i]\n",
    "            ax.pcolormesh(slx, sly, powmap[i].T)\n",
    "            ax.arrow(0, 0, slow_y, slow_x, head_width=0.005,\n",
    "                     head_length=0.01, fc='k', ec='k')\n",
    "            if array_response:\n",
    "                tslx = np.arange(sllx+slow_x, slmx+slow_x+sls, sls)\n",
    "                tsly = np.arange(slly+slow_y, slmy+slow_y+sls, sls)\n",
    "                try:\n",
    "                    ax.contour(tsly, tslx, transff.T, 5, colors='k',\n",
    "                               linewidth=0.5)\n",
    "                except:\n",
    "                    pass\n",
    "            ax.set_ylim(slx[0], slx[-1])\n",
    "            ax.set_xlim(sly[0], sly[-1])\n",
    "        new_time = t[i]\n",
    "\n",
    "        result = \"BAZ: %.2f, Slow: %.2f s/deg, Time %s\" % (\n",
    "            baz[i], slow[i], UTCDateTime(new_time))\n",
    "        ax.set_title(result)\n",
    "\n",
    "        plt.show()\n",
    "#\n",
    "#------ returns \n",
    "#\n",
    "# -------------- End of function   ---------------------\n",
    "#                                      wlen(s)\n",
    "sldtw_fk(gather, MTparam[3], MTparam[4], 5., wfrac=0.8, baz_plot=True,\\\n",
    "             slx=None, sly=None, sls=None)\n",
    "#---> wlen = 5 wfrac =0.8 => 10min processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Matched-filter detection\n",
    "- Create a catalog of **template waveforms** from file 3804 to generate characteristic functions that could be used for detection.\n",
    "- Once the catalog is created it is necessary to provide two paramters:\n",
    "1) The correlation threshold within the normalised correlation range [-1, 1]\n",
    "2)  The triger off time in s. This is the minimum distance between events.\n",
    "#### The code $\\Downarrow$ BELOW $\\Downarrow$ resets the event catalog to an empty list: it should be run at least once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ Reset event catalog\n",
    "cat   = [] #-> wavefrom catalog\n",
    "tname = [] #-> template names\n",
    "print(f\">> Event catalog reset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code $\\Downarrow$ BELOW $\\Downarrow$ can be run many times to build the catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Build a catalog of templates. \n",
    "\"\"\"\n",
    "#------ Construct catalog\n",
    "#------ Pick up a phone\n",
    "dummy = np.random.randint(1, len(st)+1)\n",
    "ent = input(f' Enter a phone [dflt=random] ')\n",
    "ent = int( ent.rstrip().split(' ')[0] ) if ent else dummy\n",
    "#------- The trace = Phone -1.\n",
    "trZ = gather[ent - 1].copy()\n",
    "#\n",
    "#------ Plot Spectrogram\n",
    "time = trZ.times(type=\"relative\")\n",
    "p.Pspect(time, trZ)\n",
    "#\n",
    "#-------- Construct catalog of template waveforms with names\n",
    "cat, tname = u.cat_wfrm(trZ, cat, tname, ent)\n",
    "#\n",
    "print(f\">> Template catalog has {len(cat)} templates: {tname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Detect events with the Matched-filter detection algorithms\n",
    "Work with a single trace. It is necessary to provide two paramters:\n",
    "- The correlation threshold within the normalised correlation range [-1, 1]\n",
    "- The triger off time in s. This is the minimum distance between events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ Import Packages\n",
    "from obspy.signal.cross_correlation import correlation_detector\n",
    "import pprint\n",
    "print(f\">> Trigger packages imported.\")\n",
    "#\n",
    "#------ Enter height and distance (s). Hint: .6 1\n",
    "ent = input(f'<< Enter correlation threshold and triger off time(s): ')\n",
    "ent = ent.rstrip().split(' ')\n",
    "corthr   = float(ent[0])\n",
    "trgoff   = float(ent[1])\n",
    "#\n",
    "stream = Stream()\n",
    "for i in range(0, len(gather), 6):\n",
    "    stream  = Stream([gather[i]])\n",
    "#\n",
    "#------ Detections. Free memory on each loop.\n",
    "    detect = []\n",
    "    for template in cat:\n",
    "        tmplstr = Stream([template])\n",
    "        dets, sims = correlation_detector(\n",
    "                       stream=stream, templates=[tmplstr],\n",
    "                       heights=corthr, distance=trgoff, plot=stream,\n",
    "                       template_names=tname )\n",
    "        detect.extend(dets)\n",
    "#\n",
    "    print(\"Trace {0} has {1} detections from {2} templates\".format(i+1, len(detect), len(cat)))\n",
    "    print(detect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing DOA with sliding-window array processing\n",
    "\n",
    "The next code block applies the least-squares method for estimating the DOA in a sliding-window. You can specify the start and end time to process, the length of the time window, and the overlap. The output is a list of times, phase velocities, and backazimuths. The subsequent plot shows the results with the beamformed waveform for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#------ Get the array coordinates\n",
    "X, stn = u.acoord(gather, bcenter)\n",
    "#\n",
    "#------ Enter the sliding-window parameters\n",
    "print(f'>> Provide the parameters for estimating the DOA with a sliding-window:')\n",
    "print(f'   1) twin         -> length of the time window;')\n",
    "print(f'   2) twstep       -> the window step')\n",
    "print(f'   3) tstart, tend -> the relative start and end times to process;')\n",
    "#\n",
    "ent = input(f'<< Enter twin, twstep, tstart, and tend: ') or '1.2 0.2 30 40'\n",
    "twin, twstep, tstart, tend = np.array(ent.rstrip().split(' '), dtype=float)\n",
    "#\n",
    "#------------ \n",
    "slid_fk = u.sldtw_fk(gather, tstart, tend, MTparam, win_len=twin, win_frac=twstep)\n",
    "#------------ Convert times to seconds after Stream start time:\n",
    "#T = (slid_fk[:,0] - date2num(st[0].stats.starttime.datetime))*86400\n",
    "\n",
    "\n",
    "#T = (slid_fk[:,0] - date2num(gather[0].stats.starttime.datetime))*86400\n",
    "T = slid_fk[:,0] - gather[0].times(\"matplotlib\")[0]\n",
    "\n",
    "\n",
    "#------------ Convert backazimuths to degrees from North:\n",
    "B = slid_fk[:,3] % 360.\n",
    "#------------ Convert slowness to phase velocity:\n",
    "V = 1/slid_fk[:,4]\n",
    "#------------ Semblance:\n",
    "S = slid_fk[:,1]\n",
    "#------------ Plot. Mwax velocity is vmax\n",
    "vmax =  1.5\n",
    "\n",
    "ent = input(f'<< Enter a phone: ')\n",
    "ent = ent.rstrip().split(' ')\n",
    "p.psw(gather, T, B, V, C=S, v_max=vmax, element=ent[0], twin_plot=[tstart,tend])\n",
    "\n",
    "#\n",
    "#------ Get a list of times, phase velocities, and backazimuths\n",
    "#T, V, B = u.sldtw(gather, X, tstart, tend, twin, overlap)\n",
    "#\n",
    "#------ Plot\n",
    "#st = u.add_beam(gather, bcenter, 'bcenter')\n",
    "#p.psw(gather, T, B, V, v_max=1., twin_plot=[tstart,tend])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent = int(ent) - 1\n",
    "flims = [MTparam[3], MTparam[4]]\n",
    "\"\"\"\n",
    "====================== BEAMFORMING ======================\n",
    "\"\"\"\n",
    "stream = Stream()\n",
    "dummy  = Stream([gather[ent]])\n",
    "print(len(dummy))\n",
    "# ---------- Use FK Analysis\n",
    "out, stime, etime = u.BeamFK(dummy, flims, ttb_gloc)\n",
    "#-- Make output human readable\n",
    "t, rel_power, abs_power, baz, slow = out.T\n",
    "#------------- print\n",
    "sys.stdout.write('\\n')\n",
    "print(f'>> t       rel_power abs_power   baz(deg) slow(s/km)')    \n",
    "for i in range(len(t)):\n",
    "    print(f'   {round(t[i],4)}, {round(rel_power[i],4)}, {round(abs_power[i],4)}, {round(baz[i],4)}, {round(slow[i],4)}')    \n",
    "#------------ Plot\n",
    "p.pltbaz(out, stime , etime)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
