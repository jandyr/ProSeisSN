{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeMSvOAPfX5S"
   },
   "source": [
    "---\n",
    "\n",
    "# Proj1: Array Methods Trigger algorithms\n",
    "\n",
    "This is a project for the Course **ProSeisSN**. It deals with real data and uses the Course's Github Repos.\n",
    "\n",
    "#### Dependencies: Obspy, Numpy, Matplotlib\n",
    "#### Reset the Jupyter/IPython notebook in order to run it again, press:\n",
    "***Kernel*** -> ***Restart & Clear Output***\n",
    "#### The code $\\Downarrow$ BELOW $\\Downarrow$ runs a notebook with other dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "uzMJ-lGlkGuK",
    "outputId": "66c27f9e-fd21-4a54-ed6d-6a23b77ec540",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#------ Import Libraries\n",
    "import sys\n",
    "import os\n",
    "    \n",
    "#------ Work with the directory structure to include auxiliary codes\n",
    "print('\\n Local directory ==> ', os.getcwd())\n",
    "print('  - Contents: ', os.listdir(), '\\n')\n",
    "\n",
    "path = os.path.abspath(os.path.join('..'))\n",
    "if path not in sys.path:\n",
    "    sys.path.append(path+\"/CodePy\")\n",
    "\n",
    "%run ../CodePy/ImpMod.ipynb\n",
    "\n",
    "#------ Alter default matplotlib rcParams\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.dates as dates\n",
    "# Change the defaults of the runtime configuration settings in the global variable matplotlib.rcParams\n",
    "plt.rcParams['figure.figsize'] = 9, 5\n",
    "#plt.rcParams['lines.linewidth'] = 0.5\n",
    "plt.rcParams[\"figure.subplot.hspace\"] = (.9)\n",
    "\n",
    "#------ Magic commands\n",
    "%matplotlib inline\n",
    "%matplotlib widget\n",
    "#%pylab notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Guide\n",
    "Esse é um guia para a realização de um trabalho do curso **ProSeisSN** tendo como base dados reais e os Jupter Notebooks do Repositório \n",
    "` https://github.com/jandyr/ProSeisSN_Nbk `\n",
    "- Sugere-se um trabalho conciso, que apresente apenas os resultados mais importantes, evitando expor material que não venha a acrescentar conteúdo relevante. Como regra geral recomenda-se classificar o material a ser incluído no texto entre: pouco, médio e muito relevante. O material julgado como pouco relevante não deve ser incluído, recomenda-se refletir antes de incluir um material de relevância média, somente incluir o que realmente contribuir à compreenção do texto.\n",
    "- Recomenda-se o uso de linguagem concisa e direta, evitando conceitos vazios do tipo: ''a partir dos dados``, ''vemos que`` etc. Tanto o Português, quanto o Inglês são aceitáveis na redação do texto.\n",
    "- Provê-se um template em Latex **Proj1.tex** que *pode, ou não* ser utilizado. a escolha é sua.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Use data files from TTB22\n",
    "Os dados vem de um experimento realizado no Rio Pará, o braço oriental do estuário do Rio Amazonas, onde as ondas sísmicas são geradas pela transferência da energia do fluxo turbulento, resultante das grandes amplitudes de suas marés, por forças friccionais às rugosidades do seu leito. Tanto as fontes, quanto os geofones estão na superfície, tornando as ondas de superfície dominantes em relação às de volume.\n",
    "- **The Receiver Array**\n",
    "The array has 24 GS-20DX vertical geophones hooked to a $L=69$m cable, using takeouts spaced $\\delta l=6$m from each other. The GS-20DX geophones have a natural frequency of $f_n=10\\textrm{Hz}$, and a spurious frequency $f_{sp}>250$Hz. The array has a irregular circular shape, deployed in the Southern tip of the island, with its center at $\\left(1^{\\circ}12^{\\prime}6.93^{\\prime\\prime}\\textrm{S},48^{\\circ}30^{\\prime}23.39^{\\prime\\prime}\\textrm{S}\\right)$. Each of the 24 gather traces are $\\Delta T=60$s long, with a sampling frequency of $f_{s}=250$Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\"\"\"\n",
    "====================== READ PHONES LOCATIONS ======================\n",
    "\"\"\"\n",
    "#------ Read the phones cartesian locations\n",
    "#--- Reads the CSV file with (x, y)m locations\n",
    "ttb_loc = u.RGloc('../Data/'+'ttb_loc.dat')\n",
    "#------ Read the phones geographic locations\n",
    "#--- Reads the CSV file with (lat,lon) in degress locations\n",
    "ttb_gloc = u.RGloc('../Data/'+'ttb_gloc.dat')\n",
    "#\n",
    "#------ Plot gather in cartesian\n",
    "p.pgather(ttb_loc[:,1], ttb_loc[:,2], ttb_loc[:,0], coord='cartesian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Read data files from TTB22\n",
    "- **The data**\n",
    "Work with 116 files, from 3695 to 3810, 2h of data em maré vazante variando 0.91m:\n",
    "| File | Timestamp | Tide (m) |\n",
    "| :-: | :-: | :-: |\n",
    "| 3695 | 2022-04-02T12:00:15 | 2.70 |\n",
    "| 3810 | 2022-04-02T14:03:06 | 1.79 |\n",
    "\n",
    "<img src=\"./ttbtide.png\" width=\"500\">\n",
    "#### Repeat the code $\\Downarrow$ BELOW $\\Downarrow$ as may times as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================== READ THE SEISMIC DATA LOCALLY ======================\n",
    "\"\"\"\n",
    "#------ Read the seismic data\n",
    "ent = str(np.random.randint(3695, 3810))\n",
    "ent = input(f'   Enter a file number in [3695, 3810], rtn=random:\\n') or ent\n",
    "ent = ent.rstrip().split(' ')\n",
    "print(f\">> Read with data file {ent}\")\n",
    "ent = '../Data/ttb22/'+ent[0]+'.dat'\n",
    "#\n",
    "#------- Read the data file as a SEG2 object\n",
    "\n",
    "print(ent)\n",
    "st = read(ent)\n",
    "#\n",
    "#------- Print stream information\n",
    "dummy = float(st[-1].stats.seg2.RECEIVER_LOCATION)\n",
    "print(f\">> Gather acquired on {st[0].stats.starttime}, has {int(st[0].stats.npts)} data points.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Display the seismogram\n",
    "- Use the experience with one trace to process the whole stream together.\n",
    "- Try other MTparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#------ Create a new stream from the SEG2 stream. Gather baricenter = bcenter\n",
    "gather, bcenter = u.creastrm(st, ttb_gloc)\n",
    "#------- Filter the stream\n",
    "#--- Filter parameters\n",
    "MTparam = [1, 1, 'bp',  5., 50., 1, 0]\n",
    "# └─────> [dtr, line, ftype, Fmin, Fmax, taper, gain]\n",
    "gather = u.otrstr(gather, MTparam)\n",
    "#\n",
    "#------ Plot\n",
    "gather.plot(type='section',\n",
    "            scale=1.3, alpha=.7,\n",
    "            orientation='horizontal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\Downarrow$ Zoom in the above seismogram $\\Downarrow$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#------ Zoom in the seismogram\n",
    "ent = input(f' Enter t0 and t1 to zoom: ')\n",
    "ent = ent.rstrip().split(' ')\n",
    "f0 = float(ent[0])\n",
    "f1 = float(ent[1])\n",
    "#\n",
    "dt = gather[0].stats.starttime\n",
    "gather.plot(type='section',\n",
    "            scale=1.3, alpha=.7,\n",
    "            starttime=dt+f0, endtime=dt+f1,\n",
    "            orientation='horizontal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Matched-filter detection\n",
    "- Create a catalog of **template waveforms** from file 3804 to generate characteristic functions that could be used for detection.\n",
    "- Once the catalog is created it is necessary to provide two paramters:\n",
    "1) The correlation threshold within the normalised correlation range [-1, 1]\n",
    "2)  The triger off time in s. This is the minimum distance between events.\n",
    "#### The code $\\Downarrow$ BELOW $\\Downarrow$ resets the event catalog to an empty list: it should be run at least once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ Reset event catalog\n",
    "cat   = [] #-> wavefrom catalog\n",
    "tname = [] #-> template names\n",
    "print(f\">> Event catalog reset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code $\\Downarrow$ BELOW $\\Downarrow$ can be run many times to build the catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Build a catalog of templates write to file wvfrm.dat\n",
    "\"\"\"\n",
    "#------ Construct catalog\n",
    "#------ Pick up a phone\n",
    "dummy = np.random.randint(1, len(st)+1)\n",
    "ent = input(f' Enter a phone [dflt=random] ')\n",
    "ent = int( ent.rstrip().split(' ')[0] ) if ent else dummy\n",
    "#------- The trace = Phone -1.\n",
    "trZ = gather[ent - 1].copy()\n",
    "#\n",
    "#-------- Construct catalog of template waveforms with names\n",
    "cat, tname = u.cat_wfrm(trZ, cat, tname, ent)\n",
    "#\n",
    "print(f\">> Template catalog has {len(cat)} templates: {tname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- Save your work when finished.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\"\"\"\n",
    "Save catalog to file name.wvf\n",
    "\"\"\" \n",
    "ent = 'cat'\n",
    "ent = input(f' Enter filename [dflt=cat.wvf] ') or ent\n",
    "ent = ent.rstrip().split(' ')\n",
    "ent = '../Data/'+ent+'.wvf'\n",
    "with open(ent, 'w') as file:\n",
    "    json.dump(data, file\n",
    "print(f\"wavefroms saved to {ent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Detect events with the Matched-filter detection algorithms\n",
    "Work with a single trace. It is necessary to provide two paramters:\n",
    "- The correlation threshold within the normalised correlation range [-1, 1]\n",
    "- The triger off time in s. This is the minimum distance between events.\n",
    "- Ref: https://docs.obspy.org/master/tutorial/code_snippets/xcorr_detector.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ Import Packages\n",
    "from obspy.signal.cross_correlation import correlation_detector\n",
    "import pprint\n",
    "print(f\">> Trigger packages imported.\")\n",
    "\"\"\"\n",
    "You can read the catalog file here if you want\n",
    "\"\"\" \n",
    "#\n",
    "#------ Enter height and distance (s). Hint: .6 1\n",
    "ent = input(f'<< Enter correlation threshold and triger off time(s): ')\n",
    "ent = ent.rstrip().split(' ')\n",
    "corthr   = float(ent[0])\n",
    "trgoff   = float(ent[1])\n",
    "#\n",
    "stream = Stream()\n",
    "for i in range(0, len(gather), 6):\n",
    "    stream  = Stream([gather[i]])\n",
    "#\n",
    "#------ Detections. Free memory on each loop.\n",
    "    detect = []\n",
    "    for template in cat:\n",
    "        tmplstr = Stream([template])\n",
    "        dets, sims = correlation_detector(\n",
    "                       stream=stream, templates=[tmplstr],\n",
    "                       heights=corthr, distance=trgoff, plot=stream,\n",
    "                       template_names=tname )\n",
    "        detect.extend(dets)\n",
    "#\n",
    "    print(\"Trace {0} has {1} detections from {2} templates\".format(i+1, len(detect), len(cat)))\n",
    "    print(detect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
